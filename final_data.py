# -*- coding: utf-8 -*-
"""
Script ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c c·ªßa h·ªá th·ªëng t√¨m ki·∫øm
- ƒê·ªçc queries t·ª´ random_queries.csv
- Ch·∫°y search_top5 cho m·ªói query
- T√≠nh Precision@K, AP@K, MAP@K d·ª±a tr√™n distance ho·∫∑c relevance score
- L∆∞u progress ƒë·ªÉ c√≥ th·ªÉ ti·∫øp t·ª•c sau
"""
import csv
import json
import re
from pathlib import Path
from typing import List, Dict, Any, Optional
from sentence_transformers import SentenceTransformer
import chromadb

BASE_DIR = Path(__file__).resolve().parent
QUERIES_FILE = BASE_DIR / "random_queries.csv"
PROGRESS_FILE = BASE_DIR / "progress_final_data.json"
RESULTS_FILE = BASE_DIR / "final_results.json"
SEARCH_RESULTS_FILE = BASE_DIR / "search_results_data.json"  # File l∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm ƒë·ªÉ ƒë√°nh gi√°
COLLECTION_NAME = "qa_collection"
BATCH_SIZE = 20  # S·ªë l∆∞·ª£ng queries x·ª≠ l√Ω m·ªói l·∫ßn ch·∫°y
AUTO_EVALUATION = True  # True = t·ª± ƒë·ªông ƒë√°nh gi√°, False = ƒë√°nh gi√° th·ªß c√¥ng
EVALUATION_METHOD = "distance"  # "distance" ho·∫∑c "relevance"
DISTANCE_THRESHOLD = 0.8  # N·∫øu d√πng distance: distance < 0.8 ‚Üí relevant
RELEVANCE_THRESHOLD = 0.5  # N·∫øu d√πng relevance: score >= 0.5 ‚Üí relevant

# Kh·ªüi t·∫°o ChromaDB client v√† collection
client = chromadb.PersistentClient(path=str(BASE_DIR / "chromadb_store"))
collection = client.get_or_create_collection(name=COLLECTION_NAME)

# Kh·ªüi t·∫°o model embedding
model = SentenceTransformer('all-MiniLM-L6-v2')


def search_top5(query: str) -> List[Dict[str, Any]]:
    """Tr·∫£ v·ªÅ t·ªëi ƒëa 5 h·ªì s∆° ph√π h·ª£p nh·∫•t v·ªõi truy v·∫•n."""
    q_emb = model.encode([query], convert_to_tensor=False)[0].tolist()
    results = collection.query(
        query_embeddings=[q_emb],
        n_results=5,
        include=["metadatas", "distances"],
    )
    items: List[Dict[str, Any]] = []
    metas_list = (results.get("metadatas") or [[]])[0]
    distance_list = (results.get("distances") or [[]])[0]
    # ids lu√¥n ƒë∆∞·ª£c tr·∫£ v·ªÅ trong response, kh√¥ng c·∫ßn include
    ids_list = (results.get("ids") or [[]])[0]
    for idx, meta in enumerate(metas_list):
        distance = distance_list[idx] if idx < len(distance_list) else None
        person_id = ids_list[idx] if idx < len(ids_list) else None
        items.append({
            "person_id": person_id,
            "title": meta.get("title", ""),
            "skills": meta.get("skills", ""),
            "abilities": meta.get("abilities", ""),
            "program": meta.get("program", ""),
            "distance": distance,
        })
    return items


def load_queries() -> List[Dict[str, str]]:
    """ƒê·ªçc t·∫•t c·∫£ queries t·ª´ file CSV."""
    queries = []
    if not QUERIES_FILE.exists():
        raise FileNotFoundError(f"File not found: {QUERIES_FILE}")
    
    with QUERIES_FILE.open("r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        for row in reader:
            queries.append({
                "query_id": row.get("query_id", ""),
                "query_text": row.get("query_text", ""),
                "category": row.get("category", ""),
                "target_person_id": row.get("target_person_id", ""),
                "difficulty": row.get("difficulty", ""),
            })
    return queries


def load_progress() -> Dict[str, Any]:
    """T·∫£i progress ƒë√£ l∆∞u (n·∫øu c√≥)."""
    if PROGRESS_FILE.exists():
        with PROGRESS_FILE.open("r", encoding="utf-8") as f:
            return json.load(f)
    return {
        "last_processed_index": 0,
        "results": []
    }


def save_progress(progress: Dict[str, Any]):
    """L∆∞u progress v√†o file."""
    with PROGRESS_FILE.open("w", encoding="utf-8") as f:
        json.dump(progress, f, ensure_ascii=False, indent=2)


def save_results(results: List[Dict[str, Any]]):
    """L∆∞u k·∫øt qu·∫£ cu·ªëi c√πng v√†o file."""
    with RESULTS_FILE.open("w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)


def load_search_results() -> List[Dict[str, Any]]:
    """T·∫£i k·∫øt qu·∫£ t√¨m ki·∫øm ƒë√£ l∆∞u (n·∫øu c√≥)."""
    if SEARCH_RESULTS_FILE.exists():
        with SEARCH_RESULTS_FILE.open("r", encoding="utf-8") as f:
            return json.load(f)
    return []


def save_search_results(search_results_data: List[Dict[str, Any]]):
    """L∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm v√†o file ƒë·ªÉ ƒë√°nh gi√°."""
    with SEARCH_RESULTS_FILE.open("w", encoding="utf-8") as f:
        json.dump(search_results_data, f, ensure_ascii=False, indent=2)


def display_results(results: List[Dict[str, Any]], query_info: Dict[str, str], query_text: str = ""):
    """Hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ki·∫øm cho ng∆∞·ªùi d√πng v·ªõi ƒë√°nh gi√° ƒë√∫ng/kh·ªõp."""
    print("\n" + "="*80)
    print(f"QUERY TH√îNG TIN")
    print("="*80)
    print(f"Query ID: {query_info['query_id']}")
    print(f"Query: {query_info['query_text']}")
    print(f"Category: {query_info['category']} | Difficulty: {query_info['difficulty']}")
    print("\n" + "-"*80)
    print("TOP 5 K·∫æT QU·∫¢ T√åM KI·∫æM")
    print("-"*80)
    
    # T√≠nh relevance labels ƒë·ªÉ hi·ªÉn th·ªã
    if EVALUATION_METHOD == "distance":
        threshold = DISTANCE_THRESHOLD
        method_desc = f"distance < {threshold}"
    else:
        threshold = RELEVANCE_THRESHOLD
        method_desc = f"relevance >= {threshold}"
    
    print(f"\nüìä Ti√™u ch√≠ ƒë√°nh gi√°: {method_desc}")
    if EVALUATION_METHOD == "distance":
        print("   üí° Distance c√†ng NH·ªé ‚Üí c√†ng gi·ªëng ‚Üí c√†ng ƒê√öNG")
    else:
        print("   üí° Relevance score c√†ng CAO ‚Üí c√†ng ph√π h·ª£p ‚Üí c√†ng ƒê√öNG")
    print("\n" + "-"*80)
    
    for idx, result in enumerate(results, 1):
        person_id = result.get('person_id', 'N/A')
        distance = result.get('distance', None)
        title = result.get('title', 'N/A')
        skills = result.get('skills', 'N/A')
        abilities = result.get('abilities', 'N/A')
        program = result.get('program', 'N/A')
        
        # X√°c ƒë·ªãnh xem k·∫øt qu·∫£ c√≥ ƒë√∫ng/kh·ªõp kh√¥ng
        is_relevant = False
        if EVALUATION_METHOD == "distance":
            if distance is not None:
                is_relevant = distance < threshold
        else:
            if query_text:
                score = calculate_relevance_score(query_text, result)
                is_relevant = score >= threshold
        
        # ƒê√°nh d·∫•u r√µ r√†ng
        status_icon = "‚úì ƒê√öNG/KH·ªöP" if is_relevant else "‚úó KH√îNG KH·ªöP"
        status_color = "‚úì" if is_relevant else "‚úó"
        
        print(f"\n{'='*80}")
        print(f"K·∫æT QU·∫¢ [{idx}/5] - {status_icon}")
        print(f"{'='*80}")
        print(f"Person ID: {person_id}")
        if distance is not None:
            relevance_info = f"Distance: {distance:.4f}"
            if EVALUATION_METHOD == "distance":
                relevance_info += f" {'‚úì' if is_relevant else '‚úó'} {'< ' if is_relevant else '‚â• '}{threshold}"
            else:
                if query_text:
                    score = calculate_relevance_score(query_text, result)
                    relevance_info += f" | Relevance: {score:.3f} {'‚úì' if is_relevant else '‚úó'} {'‚â• ' if is_relevant else '< '}{threshold}"
            print(f"{relevance_info}")
        print(f"\nüìã Title/Role:")
        print(f"   {title}")
        print(f"\nüõ†Ô∏è  Skills:")
        # Hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß skills, chia th√†nh nhi·ªÅu d√≤ng n·∫øu qu√° d√†i
        if skills and skills != 'N/A':
            # Chia th√†nh c√°c d√≤ng 80 k√Ω t·ª±
            words = skills.split(', ')
            line = ""
            for word in words:
                if len(line) + len(word) + 2 > 75:
                    if line:
                        print(f"   {line.strip()}")
                    line = word + ", "
                else:
                    line += word + ", "
            if line:
                print(f"   {line.rstrip(', ')}")
        else:
            print(f"   {skills}")
        print(f"\nüíº Abilities:")
        if abilities and abilities != 'N/A':
            # Chia th√†nh c√°c d√≤ng 80 k√Ω t·ª±
            words = abilities.split(', ')
            line = ""
            for word in words:
                if len(line) + len(word) + 2 > 75:
                    if line:
                        print(f"   {line.strip()}")
                    line = word + ", "
                else:
                    line += word + ", "
            if line:
                print(f"   {line.rstrip(', ')}")
        else:
            print(f"   {abilities}")
        print(f"\nüéì Education/Program:")
        print(f"   {program}")
    
    print("\n" + "="*80)


def extract_keywords(text: str) -> set:
    """Tr√≠ch xu·∫•t keywords t·ª´ text (lo·∫°i b·ªè stop words ƒë∆°n gi·∫£n)."""
    # Chuy·ªÉn th√†nh lowercase v√† t√°ch th√†nh t·ª´
    words = re.findall(r'\b\w+\b', text.lower())
    # Lo·∫°i b·ªè c√°c t·ª´ qu√° ng·∫Øn (< 3 k√Ω t·ª±) v√† c√°c t·ª´ th∆∞·ªùng g·∫∑p
    stop_words = {'the', 'for', 'and', 'with', 'in', 'on', 'at', 'to', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'of', 'from', 'by', 'as', 'or', 'but', 'not', 'this', 'that', 'these', 'those'}
    keywords = {w for w in words if len(w) >= 3 and w not in stop_words}
    return keywords


def calculate_relevance_score(query: str, result: Dict[str, Any]) -> float:
    """
    T√≠nh ƒëi·ªÉm relevance (0-1) d·ª±a tr√™n:
    1. Distance (semantic similarity) - 40%
    2. Keyword matching trong title - 20%
    3. Keyword matching trong skills - 25%
    4. Keyword matching trong abilities - 15%
    """
    score = 0.0
    
    # 1. Distance score (c√†ng nh·ªè c√†ng t·ªët, normalize v·ªÅ 0-1)
    distance = result.get('distance')
    if distance is not None:
        # Distance th∆∞·ªùng trong kho·∫£ng 0-2, normalize
        # Distance nh·ªè = similarity cao
        distance_score = max(0, 1 - (distance / 2.0))  # N·∫øu distance = 0 -> score = 1, distance = 2 -> score = 0
        score += distance_score * 0.4
    
    # 2-4. Keyword matching
    query_keywords = extract_keywords(query)
    
    # Title matching (20%)
    title = result.get('title', '').lower()
    title_keywords = extract_keywords(title)
    title_match = len(query_keywords & title_keywords) / max(len(query_keywords), 1)
    score += title_match * 0.2
    
    # Skills matching (25%)
    skills = result.get('skills', '').lower()
    skills_keywords = extract_keywords(skills)
    skills_match = len(query_keywords & skills_keywords) / max(len(query_keywords), 1)
    score += skills_match * 0.25
    
    # Abilities matching (15%)
    abilities = result.get('abilities', '').lower()
    abilities_keywords = extract_keywords(abilities)
    abilities_match = len(query_keywords & abilities_keywords) / max(len(query_keywords), 1)
    score += abilities_match * 0.15
    
    return min(1.0, score)


def get_relevance_labels(results: List[Dict[str, Any]], query: str, 
                         method: str = "distance", threshold: float = 0.8) -> List[int]:
    """
    X√°c ƒë·ªãnh relevance label (0 ho·∫∑c 1) cho m·ªói k·∫øt qu·∫£.
    
    Args:
        results: List of search results
        query: Query text (ƒë·ªÉ t√≠nh relevance score n·∫øu method="relevance")
        method: "distance" (ch·ªâ d√πng distance) ho·∫∑c "relevance" (d√πng relevance score)
        threshold: 
            - N·∫øu method="distance": distance threshold (c√†ng nh·ªè c√†ng t·ªët, th∆∞·ªùng 0.6-1.0)
            - N·∫øu method="relevance": relevance score threshold (0-1, c√†ng cao c√†ng t·ªët)
    
    Returns:
        List of binary relevance labels [0, 1, 0, 1, ...]
    """
    labels = []
    
    for result in results:
        is_relevant = False
        
        if method == "distance":
            # Ch·ªâ d√πng distance: distance c√†ng nh·ªè = c√†ng gi·ªëng = c√†ng ph√π h·ª£p
            distance = result.get('distance')
            if distance is not None:
                # Distance < threshold ‚Üí relevant
                is_relevant = distance < threshold
        elif method == "relevance":
            # D√πng relevance score (k·∫øt h·ª£p distance + keyword matching)
            score = calculate_relevance_score(query, result)
            is_relevant = score >= threshold
        
        labels.append(1 if is_relevant else 0)
    
    return labels


def precision_at_k(relevance_labels: List[int], k: int) -> float:
    """
    T√≠nh Precision@K.
    
    Args:
        relevance_labels: List of binary relevance labels [0, 1, 0, 1, ...]
        k: S·ªë k·∫øt qu·∫£ ƒë·∫ßu ti√™n c·∫ßn xem x√©t
    
    Returns:
        Precision@K (0.0 - 1.0)
    """
    if k == 0:
        return 0.0
    
    top_k_labels = relevance_labels[:k]
    if not top_k_labels:
        return 0.0
    
    relevant_count = sum(top_k_labels)
    return relevant_count / len(top_k_labels)


def average_precision_at_k(relevance_labels: List[int], k: int) -> float:
    """
    T√≠nh Average Precision@K (AP@K).
    
    AP@K = (1/R) * sum(P@i for i where result i is relevant)
    R = t·ªïng s·ªë k·∫øt qu·∫£ relevant trong top K
    
    Args:
        relevance_labels: List of binary relevance labels
        k: S·ªë k·∫øt qu·∫£ ƒë·∫ßu ti√™n c·∫ßn xem x√©t
    
    Returns:
        AP@K (0.0 - 1.0)
    """
    if k == 0:
        return 0.0
    
    top_k_labels = relevance_labels[:k]
    if not top_k_labels:
        return 0.0
    
    # T·ªïng s·ªë k·∫øt qu·∫£ relevant trong top K
    total_relevant = sum(top_k_labels)
    if total_relevant == 0:
        return 0.0
    
    # T√≠nh precision t·∫°i m·ªói v·ªã tr√≠ c√≥ k·∫øt qu·∫£ relevant
    ap_sum = 0.0
    relevant_found = 0
    
    for i, label in enumerate(top_k_labels, 1):
        if label == 1:  # K·∫øt qu·∫£ n√†y l√† relevant
            relevant_found += 1
            # Precision t·∫°i v·ªã tr√≠ i = s·ªë relevant t·ª´ ƒë·∫ßu ƒë·∫øn i / i
            precision_at_i = relevant_found / i
            ap_sum += precision_at_i
    
    return ap_sum / total_relevant


def calculate_metrics(results: List[Dict[str, Any]], query: str,
                     k: int = 5, method: str = "distance", threshold: float = 0.8) -> Dict[str, float]:
    """
    T√≠nh c√°c metrics: Precision@K, AP@K.
    ƒê√°nh gi√° d·ª±a tr√™n distance ho·∫∑c relevance score.
    
    Args:
        results: List of search results
        query: Query text (ƒë·ªÉ t√≠nh relevance score n·∫øu method="relevance")
        k: S·ªë k·∫øt qu·∫£ ƒë·∫ßu ti√™n (m·∫∑c ƒë·ªãnh 5)
        method: "distance" (ch·ªâ d√πng distance) ho·∫∑c "relevance" (d√πng relevance score)
        threshold: 
            - N·∫øu method="distance": distance threshold (th∆∞·ªùng 0.6-1.0)
            - N·∫øu method="relevance": relevance score threshold (0-1)
    
    Returns:
        Dict ch·ª©a c√°c metrics
    """
    relevance_labels = get_relevance_labels(results, query, method, threshold)
    
    p_at_k = precision_at_k(relevance_labels, k)
    ap_at_k = average_precision_at_k(relevance_labels, k)
    
    return {
        'precision_at_k': p_at_k,
        'ap_at_k': ap_at_k,
        'relevance_labels': relevance_labels,
        'num_relevant': sum(relevance_labels)
    }


def auto_evaluate_results(query: str, results: List[Dict[str, Any]], method: str = "combined", threshold: float = 0.5) -> int:
    """
    T·ª± ƒë·ªông ƒë√°nh gi√° s·ªë k·∫øt qu·∫£ ph√π h·ª£p.
    
    Args:
        query: Query text
        results: List of search results
        method: "distance", "keywords", ho·∫∑c "combined"
        threshold: Ng∆∞·ª°ng ƒë·ªÉ coi l√† ph√π h·ª£p (0-1)
    
    Returns:
        S·ªë k·∫øt qu·∫£ ƒë∆∞·ª£c ƒë√°nh gi√° l√† ph√π h·ª£p (0-5)
    """
    correct_count = 0
    
    for result in results:
        is_relevant = False
        
        if method == "distance":
            # Ch·ªâ d·ª±a tr√™n distance
            distance = result.get('distance')
            if distance is not None:
                # Distance < threshold * 2 (v√¨ distance th∆∞·ªùng 0-2)
                is_relevant = distance < (threshold * 2)
        
        elif method == "keywords":
            # Ch·ªâ d·ª±a tr√™n keyword matching
            score = calculate_relevance_score(query, result)
            is_relevant = score >= threshold
        
        elif method == "combined":
            # K·∫øt h·ª£p distance v√† keywords
            score = calculate_relevance_score(query, result)
            is_relevant = score >= threshold
        
        if is_relevant:
            correct_count += 1
    
    return correct_count


def get_correct_count(query: str, results: List[Dict[str, Any]], auto_mode: bool = False) -> int:
    """
    ƒê√°nh gi√° s·ªë c√¢u tr·∫£ l·ªùi ƒë√∫ng.
    N·∫øu auto_mode=True, t·ª± ƒë·ªông ƒë√°nh gi√°. N·∫øu False, y√™u c·∫ßu ng∆∞·ªùi d√πng nh·∫≠p.
    """
    if auto_mode:
        # T·ª± ƒë·ªông ƒë√°nh gi√°
        print("\n" + "="*80)
        print("ƒê√ÅNH GI√Å T·ª∞ ƒê·ªòNG")
        print("="*80)
        
        if EVALUATION_METHOD == "distance":
            print(f"ƒêang ƒë√°nh gi√° t·ª± ƒë·ªông d·ª±a tr√™n DISTANCE (distance < {DISTANCE_THRESHOLD} ‚Üí relevant)")
            print("  üí° Distance c√†ng NH·ªé ‚Üí c√†ng gi·ªëng ‚Üí c√†ng ƒë√∫ng")
            print("\nDistance c·ªßa t·ª´ng k·∫øt qu·∫£:")
            for idx, result in enumerate(results, 1):
                distance = result.get('distance', 'N/A')
                person_id = result.get('person_id', 'N/A')
                is_relevant = distance != 'N/A' and distance < DISTANCE_THRESHOLD
                status = "‚úì RELEVANT" if is_relevant else "‚úó Non-relevant"
                print(f"  [{idx}] Person ID: {person_id} | Distance: {distance:.4f} {status}")
            
            # ƒê·∫øm s·ªë relevant
            correct_count = sum(1 for r in results 
                              if r.get('distance') is not None and r.get('distance') < DISTANCE_THRESHOLD)
            print(f"\n‚úì T·ª± ƒë·ªông ƒë√°nh gi√°: {correct_count}/5 k·∫øt qu·∫£ ph√π h·ª£p (distance < {DISTANCE_THRESHOLD})")
        else:
            print(f"ƒêang ƒë√°nh gi√° t·ª± ƒë·ªông d·ª±a tr√™n RELEVANCE SCORE (score >= {RELEVANCE_THRESHOLD} ‚Üí relevant)")
            print("  üí° Relevance score c√†ng CAO ‚Üí c√†ng ph√π h·ª£p ‚Üí c√†ng ƒë√∫ng")
            print("\nRelevance score c·ªßa t·ª´ng k·∫øt qu·∫£:")
            for idx, result in enumerate(results, 1):
                score = calculate_relevance_score(query, result)
                distance = result.get('distance', 'N/A')
                person_id = result.get('person_id', 'N/A')
                is_relevant = score >= RELEVANCE_THRESHOLD
                status = "‚úì RELEVANT" if is_relevant else "‚úó Non-relevant"
                print(f"  [{idx}] Person ID: {person_id} | Distance: {distance:.4f} | Relevance: {score:.3f} {status}")
            
            # ƒê·∫øm s·ªë relevant
            correct_count = sum(1 for r in results 
                              if calculate_relevance_score(query, r) >= RELEVANCE_THRESHOLD)
            print(f"\n‚úì T·ª± ƒë·ªông ƒë√°nh gi√°: {correct_count}/5 k·∫øt qu·∫£ ph√π h·ª£p (relevance >= {RELEVANCE_THRESHOLD})")
        
        # Cho ph√©p ng∆∞·ªùi d√πng x√°c nh·∫≠n ho·∫∑c ch·ªânh s·ª≠a
        print("\nB·∫°n c√≥ mu·ªën ch·ªânh s·ª≠a k·∫øt qu·∫£ n√†y kh√¥ng? (Enter ƒë·ªÉ ch·∫•p nh·∫≠n, ho·∫∑c nh·∫≠p s·ªë 0-5):")
        user_input = input(">>> ").strip()
        
        if user_input.lower() in ['exit', 'quit', 'q']:
            return -1
        elif user_input == "":
            return correct_count
        else:
            try:
                count = int(user_input)
                if 0 <= count <= 5:
                    return count
                else:
                    print("‚ö†Ô∏è  S·ªë kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng k·∫øt qu·∫£ t·ª± ƒë·ªông.")
                    return correct_count
            except ValueError:
                print("‚ö†Ô∏è  Kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng k·∫øt qu·∫£ t·ª± ƒë·ªông.")
                return correct_count
    else:
        # ƒê√°nh gi√° th·ªß c√¥ng
        print("\n" + "="*80)
        print("ƒê√ÅNH GI√Å K·∫æT QU·∫¢")
        print("="*80)
        print("D·ª±a tr√™n c√°c ti√™u ch√≠ ƒë√£ g·ª£i √Ω ·ªü tr√™n, h√£y ƒë·∫øm s·ªë k·∫øt qu·∫£ PH√ô H·ª¢P v·ªõi query.")
        print("M·ªôt k·∫øt qu·∫£ ƒë∆∞·ª£c coi l√† PH√ô H·ª¢P n·∫øu:")
        print("  ‚úì C√≥ c√°c k·ªπ nƒÉng/c√¥ng ngh·ªá ƒë∆∞·ª£c y√™u c·∫ßu trong query")
        print("  ‚úì Ch·ª©c danh/vai tr√≤ ph√π h·ª£p v·ªõi y√™u c·∫ßu")
        print("  ‚úì B·∫±ng c·∫•p/gi√°o d·ª•c ph√π h·ª£p (n·∫øu query y√™u c·∫ßu)")
        print("  ‚úì C√≥ ƒë·ªô li√™n quan t·ªïng th·ªÉ t·ªët v·ªõi query")
        print("\nNh·∫≠p s·ªë k·∫øt qu·∫£ PH√ô H·ª¢P (0-5):")
        while True:
            try:
                count = input(">>> ").strip()
                if count.lower() in ['exit', 'quit', 'q']:
                    return -1  # Signal ƒë·ªÉ d·ª´ng
                count = int(count)
                if 0 <= count <= 5:
                    return count
                else:
                    print("‚ö†Ô∏è  Vui l√≤ng nh·∫≠p s·ªë t·ª´ 0 ƒë·∫øn 5!")
            except ValueError:
                print("‚ö†Ô∏è  Vui l√≤ng nh·∫≠p m·ªôt s·ªë h·ª£p l·ªá!")


def process_queries():
    """X·ª≠ l√Ω queries t·ª´ file CSV."""
    # ƒê·ªçc queries
    print("ƒêang ƒë·ªçc queries t·ª´ file...")
    all_queries = load_queries()
    print(f"T·ªïng s·ªë queries: {len(all_queries)}")
    
    # T·∫£i progress
    progress = load_progress()
    start_index = progress["last_processed_index"]
    results = progress["results"]
    
    # T·∫£i k·∫øt qu·∫£ t√¨m ki·∫øm ƒë√£ l∆∞u
    search_results_data = load_search_results()
    
    print(f"\nTi·∫øp t·ª•c t·ª´ query th·ª© {start_index + 1} (ƒë√£ x·ª≠ l√Ω {len(results)} queries)")
    
    # X√°c ƒë·ªãnh s·ªë queries c·∫ßn x·ª≠ l√Ω trong batch n√†y
    end_index = min(start_index + BATCH_SIZE, len(all_queries))
    queries_to_process = all_queries[start_index:end_index]
    
    print(f"S·∫Ω x·ª≠ l√Ω {len(queries_to_process)} queries (t·ª´ {start_index + 1} ƒë·∫øn {end_index})")
    print(f"B·∫°n c√≥ th·ªÉ nh·∫≠p 'exit' ho·∫∑c 'quit' b·∫•t c·ª© l√∫c n√†o ƒë·ªÉ d·ª´ng v√† l∆∞u progress\n")
    
    # X·ª≠ l√Ω t·ª´ng query
    for idx, query_info in enumerate(queries_to_process, start=start_index):
        query_text = query_info["query_text"]
        
        if not query_text.strip():
            print(f"\nQuery {idx + 1} b·ªè qua (query_text r·ªóng)")
            continue
        
        print(f"\n[{idx + 1}/{len(all_queries)}] ƒêang x·ª≠ l√Ω query...")
        
        # T√¨m ki·∫øm
        search_results = search_top5(query_text)
        
        # L∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm v√†o file ƒë·ªÉ ƒë√°nh gi√°
        search_result_entry = {
            "query_id": query_info["query_id"],
            "query_text": query_text,
            "category": query_info["category"],
            "target_person_id": query_info["target_person_id"],
            "difficulty": query_info["difficulty"],
            "search_results": search_results,
            "timestamp": None  # C√≥ th·ªÉ th√™m timestamp n·∫øu c·∫ßn
        }
        # Ki·ªÉm tra xem query_id ƒë√£ t·ªìn t·∫°i ch∆∞a (tr√°nh tr√πng l·∫∑p khi ti·∫øp t·ª•c)
        existing_idx = next((i for i, item in enumerate(search_results_data) 
                            if item.get("query_id") == query_info["query_id"]), None)
        if existing_idx is not None:
            search_results_data[existing_idx] = search_result_entry
        else:
            search_results_data.append(search_result_entry)
        save_search_results(search_results_data)
        
        if not search_results:
            print("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o!")
            metrics = {
                'precision_at_k': 0.0,
                'ap_at_k': 0.0,
                'relevance_labels': [0, 0, 0, 0, 0],
                'num_relevant': 0
            }
        else:
            # Hi·ªÉn th·ªã k·∫øt qu·∫£ (truy·ªÅn query_text ƒë·ªÉ t√≠nh relevance n·∫øu c·∫ßn)
            display_results(search_results, query_info, query_text)
            
            # T√≠nh metrics (Precision@K, AP@K)
            if EVALUATION_METHOD == "distance":
                threshold = DISTANCE_THRESHOLD
                method_desc = f"distance < {threshold}"
            else:
                threshold = RELEVANCE_THRESHOLD
                method_desc = f"relevance score >= {threshold}"
            
            metrics = calculate_metrics(
                search_results, 
                query=query_text,
                k=5,
                method=EVALUATION_METHOD,
                threshold=threshold
            )
            
            # Hi·ªÉn th·ªã metrics
            print("\n" + "="*80)
            print(f"METRICS ƒê√ÅNH GI√Å (d·ª±a tr√™n {EVALUATION_METHOD}, {method_desc})")
            print("="*80)
            print(f"Precision@5: {metrics['precision_at_k']:.4f} ({metrics['num_relevant']}/5 relevant)")
            print(f"AP@5 (Average Precision@5): {metrics['ap_at_k']:.4f}")
            print(f"Relevance labels: {metrics['relevance_labels']}")
            
            print(f"\nüí° C√ÅC METRICS ƒê∆Ø·ª¢C T√çNH D·ª∞A TR√äN:")
            print(f"   1. Precision@K: T·ª∑ l·ªá k·∫øt qu·∫£ relevant trong top K")
            print(f"   2. AP@K (Average Precision@K): Trung b√¨nh precision t·∫°i c√°c v·ªã tr√≠ c√≥ k·∫øt qu·∫£ relevant")
            print(f"   3. MAP@K (Mean Average Precision@K): Trung b√¨nh c·ªßa t·∫•t c·∫£ AP@K qua t·∫•t c·∫£ queries")
            print(f"   (MAP@K s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã khi ho√†n th√†nh t·∫•t c·∫£ queries)")
            
            if EVALUATION_METHOD == "distance":
                print(f"\nüìä Ti√™u ch√≠ x√°c ƒë·ªãnh relevant: distance < {DISTANCE_THRESHOLD}")
                print(f"   (Distance c√†ng nh·ªè ‚Üí c√†ng gi·ªëng ‚Üí c√†ng ƒë√∫ng)")
            else:
                print(f"\nüìä Ti√™u ch√≠ x√°c ƒë·ªãnh relevant: relevance score >= {RELEVANCE_THRESHOLD}")
                print(f"   (Relevance score = distance 40% + keyword matching 60%)")
            
            # ƒê√°nh gi√° (t·ª± ƒë·ªông ho·∫∑c th·ªß c√¥ng) - gi·ªØ l·∫°i ƒë·ªÉ t∆∞∆°ng th√≠ch (kh√¥ng d√πng cho metrics)
            correct_count = get_correct_count(query_text, search_results, auto_mode=AUTO_EVALUATION)
            
            if correct_count == -1:
                print("\nƒê√£ d·ª´ng. ƒêang l∆∞u progress...")
                progress["last_processed_index"] = idx
                progress["results"] = results
                save_progress(progress)
                print(f"ƒê√£ l∆∞u progress. ƒê√£ x·ª≠ l√Ω {len(results)} queries.")
                print(f"ƒê√£ l∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm v√†o: {SEARCH_RESULTS_FILE}")
                return
        
        # L∆∞u k·∫øt qu·∫£ (ch·ªâ d√πng metrics, kh√¥ng d√πng accuracy)
        result_entry = {
            "query_id": query_info["query_id"],
            "query_text": query_text,
            "category": query_info["category"],
            "target_person_id": query_info["target_person_id"],
            "difficulty": query_info["difficulty"],
            "precision_at_5": metrics['precision_at_k'],
            "ap_at_5": metrics['ap_at_k'],
            "relevance_labels": metrics['relevance_labels'],
            "num_relevant": metrics['num_relevant'],
            "search_results": search_results
        }
        results.append(result_entry)
        
        # L∆∞u progress sau m·ªói query
        progress["last_processed_index"] = idx + 1
        progress["results"] = results
        save_progress(progress)
        
        print(f"‚úì ƒê√£ l∆∞u. Precision@5: {metrics['precision_at_k']:.4f} ({metrics['num_relevant']}/5)")
        print(f"‚úì ƒê√£ l∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm v√†o file: {SEARCH_RESULTS_FILE.name}")
    
    # Ki·ªÉm tra xem ƒë√£ x·ª≠ l√Ω h·∫øt ch∆∞a
    if end_index >= len(all_queries):
        print("\n" + "="*80)
        print("ƒê√É X·ª¨ L√ù H·∫æT T·∫§T C·∫¢ QUERIES!")
        print("="*80)
        
        # T√≠nh th·ªëng k√™
        total = len(results)
        if total > 0:
            # T√≠nh MAP@5 (Mean Average Precision@5)
            ap_scores = [r.get("ap_at_5", 0.0) for r in results]
            map_at_5 = sum(ap_scores) / total if total > 0 else 0.0
            
            # T√≠nh Precision@5 trung b√¨nh
            precision_scores = [r.get("precision_at_5", 0.0) for r in results]
            avg_precision_at_5 = sum(precision_scores) / total if total > 0 else 0.0
            
            # Ph√¢n t√≠ch ph√¢n ph·ªëi Precision@5
            precision_sorted = sorted(precision_scores)
            min_precision = min(precision_scores)
            max_precision = max(precision_scores)
            median_precision = precision_sorted[total // 2] if total > 0 else 0.0
            
            # ƒê·∫øm s·ªë queries theo m·ª©c Precision@5
            perfect_queries = sum(1 for p in precision_scores if p == 1.0)
            high_queries = sum(1 for p in precision_scores if 0.8 <= p < 1.0)
            medium_queries = sum(1 for p in precision_scores if 0.5 <= p < 0.8)
            low_queries = sum(1 for p in precision_scores if p < 0.5)
            
            # Ph√¢n t√≠ch ph√¢n ph·ªëi AP@5
            ap_sorted = sorted(ap_scores)
            min_ap = min(ap_scores)
            max_ap = max(ap_scores)
            median_ap = ap_sorted[total // 2] if total > 0 else 0.0
            
            # Ph√¢n t√≠ch s·ªë l∆∞·ª£ng relevant results
            all_num_relevant = [r.get("num_relevant", 0) for r in results]
            avg_relevant = sum(all_num_relevant) / total if total > 0 else 0.0
            total_relevant_all = sum(all_num_relevant)
            max_possible = total * 5  # M·ªói query c√≥ 5 k·∫øt qu·∫£
            
            # Ph√¢n t√≠ch distance (n·∫øu c√≥)
            all_distances = []
            for r in results:
                for sr in r.get("search_results", []):
                    dist = sr.get("distance")
                    if dist is not None:
                        all_distances.append(dist)
            
            print(f"\nT·ªïng s·ªë queries ƒë√£ x·ª≠ l√Ω: {total}")
            print(f"\n{'='*80}")
            print("METRICS T·ªîNG K·∫æT")
            print(f"{'='*80}")
            print(f"Precision@5 trung b√¨nh: {avg_precision_at_5:.4f}")
            print(f"MAP@5 (Mean Average Precision@5): {map_at_5:.4f}")
            
            print(f"\n{'='*80}")
            print("PH√ÇN T√çCH CHI TI·∫æT PRECISION@5")
            print(f"{'='*80}")
            print(f"Min: {min_precision:.4f} | Max: {max_precision:.4f} | Median: {median_precision:.4f}")
            print(f"\nPh√¢n b·ªë Precision@5:")
            print(f"  Perfect (1.0000): {perfect_queries} queries ({perfect_queries/total*100:.1f}%)")
            print(f"  High (0.80-0.99): {high_queries} queries ({high_queries/total*100:.1f}%)")
            print(f"  Medium (0.50-0.79): {medium_queries} queries ({medium_queries/total*100:.1f}%)")
            print(f"  Low (<0.50): {low_queries} queries ({low_queries/total*100:.1f}%)")
            
            print(f"\n{'='*80}")
            print("PH√ÇN T√çCH CHI TI·∫æT AP@5")
            print(f"{'='*80}")
            print(f"Min: {min_ap:.4f} | Max: {max_ap:.4f} | Median: {median_ap:.4f}")
            
            print(f"\n{'='*80}")
            print("PH√ÇN T√çCH S·ªê L∆Ø·ª¢NG RELEVANT RESULTS")
            print(f"{'='*80}")
            print(f"T·ªïng s·ªë k·∫øt qu·∫£ relevant: {total_relevant_all}/{max_possible}")
            print(f"T·ª∑ l·ªá relevant: {total_relevant_all/max_possible*100:.2f}%")
            print(f"S·ªë l∆∞·ª£ng relevant trung b√¨nh m·ªói query: {avg_relevant:.2f}/5")
            
            if all_distances:
                avg_distance = sum(all_distances) / len(all_distances)
                min_distance = min(all_distances)
                max_distance = max(all_distances)
                distance_sorted = sorted(all_distances)
                median_distance = distance_sorted[len(distance_sorted) // 2]
                
                print(f"\n{'='*80}")
                print("PH√ÇN T√çCH DISTANCE")
                print(f"{'='*80}")
                print(f"Distance trung b√¨nh: {avg_distance:.4f}")
                print(f"Min: {min_distance:.4f} | Max: {max_distance:.4f} | Median: {median_distance:.4f}")
                if EVALUATION_METHOD == "distance":
                    relevant_distances = [d for d in all_distances if d < DISTANCE_THRESHOLD]
                    non_relevant_distances = [d for d in all_distances if d >= DISTANCE_THRESHOLD]
                    print(f"\nV·ªõi threshold = {DISTANCE_THRESHOLD}:")
                    print(f"  Relevant: {len(relevant_distances)} k·∫øt qu·∫£ ({len(relevant_distances)/len(all_distances)*100:.1f}%)")
                    print(f"  Non-relevant: {len(non_relevant_distances)} k·∫øt qu·∫£ ({len(non_relevant_distances)/len(all_distances)*100:.1f}%)")
                    if relevant_distances:
                        print(f"  Distance trung b√¨nh c·ªßa relevant: {sum(relevant_distances)/len(relevant_distances):.4f}")
                    if non_relevant_distances:
                        print(f"  Distance trung b√¨nh c·ªßa non-relevant: {sum(non_relevant_distances)/len(non_relevant_distances):.4f}")
            
            # Th·ªëng k√™ theo category
            category_stats = {}
            for r in results:
                cat = r["category"]
                if cat not in category_stats:
                    category_stats[cat] = {
                        "count": 0, 
                        "total_precision": 0,
                        "total_ap": 0
                    }
                category_stats[cat]["count"] += 1
                category_stats[cat]["total_precision"] += r.get("precision_at_5", 0.0)
                category_stats[cat]["total_ap"] += r.get("ap_at_5", 0.0)
            
            # Top queries t·ªët nh·∫•t v√† x·∫•u nh·∫•t
            results_with_scores = [(r, r.get("precision_at_5", 0.0), r.get("ap_at_5", 0.0)) for r in results]
            results_with_scores.sort(key=lambda x: (x[1], x[2]), reverse=True)
            
            print(f"\n{'='*80}")
            print("TOP 5 QUERIES T·ªêT NH·∫§T (theo Precision@5)")
            print(f"{'='*80}")
            for i, (r, prec, ap) in enumerate(results_with_scores[:5], 1):
                print(f"{i}. Query ID: {r['query_id']} | Category: {r['category']} | Difficulty: {r['difficulty']}")
                print(f"   Precision@5: {prec:.4f} | AP@5: {ap:.4f} | Relevant: {r.get('num_relevant', 0)}/5")
                print(f"   Query: {r['query_text'][:80]}...")
            
            print(f"\n{'='*80}")
            print("TOP 5 QUERIES X·∫§U NH·∫§T (theo Precision@5)")
            print(f"{'='*80}")
            for i, (r, prec, ap) in enumerate(results_with_scores[-5:], 1):
                print(f"{i}. Query ID: {r['query_id']} | Category: {r['category']} | Difficulty: {r['difficulty']}")
                print(f"   Precision@5: {prec:.4f} | AP@5: {ap:.4f} | Relevant: {r.get('num_relevant', 0)}/5")
                print(f"   Query: {r['query_text'][:80]}...")
            
            print(f"\n{'='*80}")
            print("TH·ªêNG K√ä THEO CATEGORY")
            print(f"{'='*80}")
            for cat, stats in sorted(category_stats.items()):
                avg_prec = stats["total_precision"] / stats["count"]
                avg_ap = stats["total_ap"] / stats["count"]
                # T√≠nh min, max cho category n√†y
                cat_precisions = [r.get("precision_at_5", 0.0) for r in results if r["category"] == cat]
                cat_min = min(cat_precisions) if cat_precisions else 0.0
                cat_max = max(cat_precisions) if cat_precisions else 0.0
                cat_perfect = sum(1 for p in cat_precisions if p == 1.0)
                print(f"  {cat} (n={stats['count']}):")
                print(f"    Precision@5: {avg_prec:.4f} (min: {cat_min:.4f}, max: {cat_max:.4f}, perfect: {cat_perfect})")
                print(f"    AP@5: {avg_ap:.4f}")
            
            # Th·ªëng k√™ theo difficulty
            difficulty_stats = {}
            for r in results:
                diff = r["difficulty"]
                if diff not in difficulty_stats:
                    difficulty_stats[diff] = {
                        "count": 0, 
                        "total_precision": 0,
                        "total_ap": 0
                    }
                difficulty_stats[diff]["count"] += 1
                difficulty_stats[diff]["total_precision"] += r.get("precision_at_5", 0.0)
                difficulty_stats[diff]["total_ap"] += r.get("ap_at_5", 0.0)
            
            print(f"\n{'='*80}")
            print("TH·ªêNG K√ä THEO DIFFICULTY")
            print(f"{'='*80}")
            for diff, stats in sorted(difficulty_stats.items()):
                avg_prec = stats["total_precision"] / stats["count"]
                avg_ap = stats["total_ap"] / stats["count"]
                # T√≠nh min, max cho difficulty n√†y
                diff_precisions = [r.get("precision_at_5", 0.0) for r in results if r["difficulty"] == diff]
                diff_min = min(diff_precisions) if diff_precisions else 0.0
                diff_max = max(diff_precisions) if diff_precisions else 0.0
                diff_perfect = sum(1 for p in diff_precisions if p == 1.0)
                print(f"  {diff} (n={stats['count']}):")
                print(f"    Precision@5: {avg_prec:.4f} (min: {diff_min:.4f}, max: {diff_max:.4f}, perfect: {diff_perfect})")
                print(f"    AP@5: {avg_ap:.4f}")
            
            # Ph√¢n t√≠ch v√† ƒë·ªÅ xu·∫•t threshold
            if EVALUATION_METHOD == "distance" and all_distances:
                print(f"\n{'='*80}")
                print("PH√ÇN T√çCH V√Ä ƒê·ªÄ XU·∫§T THRESHOLD")
                print(f"{'='*80}")
                print(f"Threshold hi·ªán t·∫°i: {DISTANCE_THRESHOLD}")
                print(f"\nPh√¢n t√≠ch v·ªõi c√°c threshold kh√°c nhau:")
                test_thresholds = [0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]
                for thresh in test_thresholds:
                    relevant_count = sum(1 for d in all_distances if d < thresh)
                    relevant_pct = relevant_count / len(all_distances) * 100
                    print(f"  Threshold {thresh:.2f}: {relevant_count}/{len(all_distances)} relevant ({relevant_pct:.1f}%)")
                
                # ƒê·ªÅ xu·∫•t threshold d·ª±a tr√™n ph√¢n v·ªã
                if len(all_distances) >= 10:
                    p25 = distance_sorted[len(distance_sorted) // 4]
                    p50 = median_distance
                    p75 = distance_sorted[len(distance_sorted) * 3 // 4]
                    print(f"\nPh√¢n v·ªã distance:")
                    print(f"  25th percentile (P25): {p25:.4f}")
                    print(f"  50th percentile (Median): {p50:.4f}")
                    print(f"  75th percentile (P75): {p75:.4f}")
                    print(f"\nüí° ƒê·ªÅ xu·∫•t:")
                    print(f"  - Threshold ch·∫∑t ch·∫Ω (P25): {p25:.4f} ‚Üí ~{sum(1 for d in all_distances if d < p25)/len(all_distances)*100:.1f}% relevant")
                    print(f"  - Threshold v·ª´a ph·∫£i (P50): {p50:.4f} ‚Üí ~{sum(1 for d in all_distances if d < p50)/len(all_distances)*100:.1f}% relevant")
                    print(f"  - Threshold l·ªèng (P75): {p75:.4f} ‚Üí ~{sum(1 for d in all_distances if d < p75)/len(all_distances)*100:.1f}% relevant")
            
            # T√≥m t·∫Øt cu·ªëi c√πng
            print(f"\n{'='*80}")
            print("T√ìM T·∫ÆT ƒê√ÅNH GI√Å")
            print(f"{'='*80}")
            print(f"üìä T·ªïng quan:")
            print(f"   - T·ªïng s·ªë queries: {total}")
            print(f"   - Precision@5 trung b√¨nh: {avg_precision_at_5:.4f} ({avg_precision_at_5*100:.2f}%)")
            print(f"   - MAP@5: {map_at_5:.4f} ({map_at_5*100:.2f}%)")
            print(f"   - S·ªë queries ƒë·∫°t perfect (1.0): {perfect_queries}/{total} ({perfect_queries/total*100:.1f}%)")
            print(f"   - S·ªë queries c√≥ Precision@5 >= 0.8: {perfect_queries + high_queries}/{total} ({(perfect_queries + high_queries)/total*100:.1f}%)")
            print(f"\nüìà Ch·∫•t l∆∞·ª£ng:")
            if avg_precision_at_5 >= 0.9:
                print(f"   ‚úì H·ªá th·ªëng ho·∫°t ƒë·ªông R·∫§T T·ªêT (Precision@5 >= 90%)")
            elif avg_precision_at_5 >= 0.8:
                print(f"   ‚úì H·ªá th·ªëng ho·∫°t ƒë·ªông T·ªêT (Precision@5 >= 80%)")
            elif avg_precision_at_5 >= 0.7:
                print(f"   ‚ö† H·ªá th·ªëng ho·∫°t ƒë·ªông KH√Å (Precision@5 >= 70%)")
            else:
                print(f"   ‚ö† H·ªá th·ªëng c·∫ßn C·∫¢I THI·ªÜN (Precision@5 < 70%)")
            
            if EVALUATION_METHOD == "distance":
                print(f"\n‚öôÔ∏è  C·∫•u h√¨nh ƒë√°nh gi√°:")
                print(f"   - Ph∆∞∆°ng ph√°p: Distance-based")
                print(f"   - Threshold: {DISTANCE_THRESHOLD}")
                print(f"   - Ti√™u ch√≠: distance < {DISTANCE_THRESHOLD} ‚Üí relevant")
            else:
                print(f"\n‚öôÔ∏è  C·∫•u h√¨nh ƒë√°nh gi√°:")
                print(f"   - Ph∆∞∆°ng ph√°p: Relevance score-based")
                print(f"   - Threshold: {RELEVANCE_THRESHOLD}")
                print(f"   - Ti√™u ch√≠: relevance score >= {RELEVANCE_THRESHOLD} ‚Üí relevant")
        
        # L∆∞u k·∫øt qu·∫£ cu·ªëi c√πng
        save_results(results)
        print(f"\nƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {RESULTS_FILE}")
        print(f"ƒê√£ l∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm ƒë·ªÉ ƒë√°nh gi√° v√†o: {SEARCH_RESULTS_FILE}")
        
        # X√≥a file progress v√¨ ƒë√£ xong
        if PROGRESS_FILE.exists():
            PROGRESS_FILE.unlink()
            print("ƒê√£ x√≥a file progress.")
    else:
        print(f"\nƒê√£ x·ª≠ l√Ω {len(queries_to_process)} queries trong batch n√†y.")
        print(f"C√≤n l·∫°i {len(all_queries) - end_index} queries.")
        print(f"Ch·∫°y l·∫°i script ƒë·ªÉ ti·∫øp t·ª•c t·ª´ query {end_index + 1}")


if __name__ == "__main__":
    try:
        process_queries()
    except KeyboardInterrupt:
        print("\n\nƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng (Ctrl+C). Progress ƒë√£ ƒë∆∞·ª£c l∆∞u.")
    except Exception as e:
        print(f"\nL·ªói: {e}")
        import traceback
        traceback.print_exc()

