# -*- coding: utf-8 -*-
"""
Script ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c c·ªßa h·ªá th·ªëng t√¨m ki·∫øm semantic v·ªõi ChromaDB

Ch·ª©c nƒÉng:
- ƒê·ªçc c√°c c√¢u truy v·∫•n t·ª´ file CSV
- T√¨m ki·∫øm top 5 h·ªì s∆° ph√π h·ª£p nh·∫•t cho m·ªói query
- T√≠nh c√°c ch·ªâ s·ªë ƒë√°nh gi√° (Precision@K, AP@K, MAP@K)
- L∆∞u ti·∫øn tr√¨nh ƒë·ªÉ c√≥ th·ªÉ ti·∫øp t·ª•c sau khi d·ª´ng
"""
import csv
import json
import re
from pathlib import Path
from typing import List, Dict, Any, Optional
from sentence_transformers import SentenceTransformer
import chromadb

# ============================================================================
# C·∫§U H√åNH
# ============================================================================

BASE_DIR = Path(__file__).resolve().parent

# C√°c file c·∫ßn d√πng
QUERIES_FILE = BASE_DIR / "random_queries.csv"              # File ch·ª©a queries
PROGRESS_FILE = BASE_DIR / "progress_final_data.json"       # File l∆∞u ti·∫øn tr√¨nh
RESULTS_FILE = BASE_DIR / "final_results.json"              # File k·∫øt qu·∫£ cu·ªëi c√πng
SEARCH_RESULTS_FILE = BASE_DIR / "search_results_data.json" # File l∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm

COLLECTION_NAME = "qa_collection"  # T√™n collection trong ChromaDB

# C·∫•u h√¨nh
BATCH_SIZE = 20  # X·ª≠ l√Ω 20 queries m·ªói l·∫ßn ch·∫°y
AUTO_EVALUATION = True  # T·ª± ƒë·ªông ƒë√°nh gi√° (True) ho·∫∑c th·ªß c√¥ng (False)
EVALUATION_METHOD = "distance"  # C√°ch ƒë√°nh gi√°: "distance" ho·∫∑c "relevance"
DISTANCE_THRESHOLD = 0.8  # N·∫øu distance < 0.8 th√¨ coi l√† ph√π h·ª£p
RELEVANCE_THRESHOLD = 0.5  # N·∫øu relevance score >= 0.5 th√¨ coi l√† ph√π h·ª£p

# K·∫øt n·ªëi ChromaDB v√† kh·ªüi t·∫°o model
client = chromadb.PersistentClient(path=str(BASE_DIR / "chromadb_store"))
collection = client.get_or_create_collection(name=COLLECTION_NAME)
model = SentenceTransformer('all-MiniLM-L6-v2')  # Model ƒë·ªÉ chuy·ªÉn text th√†nh vector


# ============================================================================
# H√ÄM T√åM KI·∫æM
# ============================================================================

def search_top5(query: str) -> List[Dict[str, Any]]:
    """
    T√¨m ki·∫øm top 5 h·ªì s∆° ph√π h·ª£p nh·∫•t v·ªõi query.
    
    C√°ch ho·∫°t ƒë·ªông:
    1. Chuy·ªÉn query th√†nh vector (embedding) - vector n√†y bi·ªÉu di·ªÖn ng·ªØ nghƒ©a c·ªßa c√¢u
    2. So s√°nh vector n√†y v·ªõi t·∫•t c·∫£ vector c·ªßa h·ªì s∆° trong database
    3. L·∫•y 5 h·ªì s∆° c√≥ distance nh·ªè nh·∫•t (t·ª©c l√† gi·ªëng nh·∫•t v·ªÅ m·∫∑t ng·ªØ nghƒ©a)
    """
    # B∆∞·ªõc 1: Chuy·ªÉn query th√†nh vector (embedding)
    # Model SentenceTransformer s·∫Ω chuy·ªÉn text th√†nh m·ªôt m·∫£ng s·ªë (vector)
    # V√≠ d·ª•: "Python developer" ‚Üí [0.1, -0.3, 0.5, ...] (384 s·ªë)
    # C√°c c√¢u c√≥ nghƒ©a gi·ªëng nhau s·∫Ω c√≥ vector g·∫ßn gi·ªëng nhau
    q_emb = model.encode([query], convert_to_tensor=False)[0].tolist()
    
    # B∆∞·ªõc 2: T√¨m ki·∫øm trong ChromaDB
    # ChromaDB s·∫Ω t√≠nh kho·∫£ng c√°ch (distance) gi·ªØa vector query v√† t·∫•t c·∫£ vector h·ªì s∆°
    # Distance c√†ng nh·ªè = c√†ng gi·ªëng nhau v·ªÅ m·∫∑t ng·ªØ nghƒ©a
    # Tr·∫£ v·ªÅ 5 h·ªì s∆° c√≥ distance nh·ªè nh·∫•t (gi·ªëng nh·∫•t)
    results = collection.query(
        query_embeddings=[q_emb],  # Vector c·ªßa query ƒë·ªÉ so s√°nh
        n_results=5,               # Ch·ªâ l·∫•y 5 k·∫øt qu·∫£ t·ªët nh·∫•t
        include=["metadatas", "distances"],  # C·∫ßn metadata (th√¥ng tin h·ªì s∆°) v√† distances (ƒë·ªô t∆∞∆°ng ƒë·ªìng)
    )
    
    # B∆∞·ªõc 3: X·ª≠ l√Ω k·∫øt qu·∫£ tr·∫£ v·ªÅ t·ª´ ChromaDB
    # ChromaDB tr·∫£ v·ªÅ d·ªØ li·ªáu d·∫°ng nested list, c·∫ßn l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n
    items: List[Dict[str, Any]] = []
    metas_list = (results.get("metadatas") or [[]])[0]      # Th√¥ng tin chi ti·∫øt c·ªßa t·ª´ng h·ªì s∆°
    distance_list = (results.get("distances") or [[]])[0]    # ƒê·ªô t∆∞∆°ng ƒë·ªìng (c√†ng nh·ªè c√†ng gi·ªëng)
    ids_list = (results.get("ids") or [[]])[0]              # ID c·ªßa t·ª´ng h·ªì s∆°
    
    # B∆∞·ªõc 4: T·∫°o danh s√°ch k·∫øt qu·∫£ v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin
    # Duy·ªát qua t·ª´ng k·∫øt qu·∫£ v√† l·∫•y th√¥ng tin c·∫ßn thi·∫øt
    for idx, meta in enumerate(metas_list):
        distance = distance_list[idx] if idx < len(distance_list) else None
        person_id = ids_list[idx] if idx < len(ids_list) else None
        
        # T·∫°o dictionary ch·ª©a th√¥ng tin ƒë·∫ßy ƒë·ªß c·ªßa h·ªì s∆°
        items.append({
            "person_id": person_id,        # ID c·ªßa ng∆∞·ªùi
            "title": meta.get("title", ""),        # Ch·ª©c danh/vai tr√≤ c√¥ng vi·ªác
            "skills": meta.get("skills", ""),      # K·ªπ nƒÉng (v√≠ d·ª•: Python, Java, SQL)
            "abilities": meta.get("abilities", ""), # Kh·∫£ nƒÉng (v√≠ d·ª•: teamwork, leadership)
            "program": meta.get("program", ""),     # B·∫±ng c·∫•p/ch∆∞∆°ng tr√¨nh h·ªçc
            "distance": distance,                   # ƒê·ªô t∆∞∆°ng ƒë·ªìng: c√†ng nh·ªè c√†ng gi·ªëng query
        })
    return items


# ============================================================================
# H√ÄM ƒê·ªåC/GHI FILE
# ============================================================================

def load_queries() -> List[Dict[str, str]]:
    """ƒê·ªçc t·∫•t c·∫£ queries t·ª´ file CSV."""
    queries = []
    if not QUERIES_FILE.exists():
        raise FileNotFoundError(f"File not found: {QUERIES_FILE}")
    
    with QUERIES_FILE.open("r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        for row in reader:
            queries.append({
                "query_id": row.get("query_id", ""),
                "query_text": row.get("query_text", ""),
                "category": row.get("category", ""),
                "target_person_id": row.get("target_person_id", ""),
                "difficulty": row.get("difficulty", ""),
            })
    return queries


def load_progress() -> Dict[str, Any]:
    """T·∫£i ti·∫øn tr√¨nh ƒë√£ l∆∞u (n·∫øu c√≥) ƒë·ªÉ ti·∫øp t·ª•c t·ª´ n∆°i ƒë√£ d·ª´ng."""
    if PROGRESS_FILE.exists():
        with PROGRESS_FILE.open("r", encoding="utf-8") as f:
            return json.load(f)
    return {
        "last_processed_index": 0,
        "results": []
    }


def save_progress(progress: Dict[str, Any]):
    """L∆∞u ti·∫øn tr√¨nh v√†o file ƒë·ªÉ c√≥ th·ªÉ ti·∫øp t·ª•c sau."""
    with PROGRESS_FILE.open("w", encoding="utf-8") as f:
        json.dump(progress, f, ensure_ascii=False, indent=2)


def save_results(results: List[Dict[str, Any]]):
    """L∆∞u k·∫øt qu·∫£ cu·ªëi c√πng v√†o file."""
    with RESULTS_FILE.open("w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)


def load_search_results() -> List[Dict[str, Any]]:
    """T·∫£i k·∫øt qu·∫£ t√¨m ki·∫øm ƒë√£ l∆∞u."""
    if SEARCH_RESULTS_FILE.exists():
        with SEARCH_RESULTS_FILE.open("r", encoding="utf-8") as f:
            return json.load(f)
    return []


def save_search_results(search_results_data: List[Dict[str, Any]]):
    """L∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm v√†o file."""
    with SEARCH_RESULTS_FILE.open("w", encoding="utf-8") as f:
        json.dump(search_results_data, f, ensure_ascii=False, indent=2)


def display_results(results: List[Dict[str, Any]], query_info: Dict[str, str], query_text: str = ""):
    """Hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ki·∫øm cho ng∆∞·ªùi d√πng v·ªõi ƒë√°nh gi√° ƒë√∫ng/kh·ªõp."""
    print("\n" + "="*80)
    print(f"QUERY TH√îNG TIN")
    print("="*80)
    print(f"Query ID: {query_info['query_id']}")
    print(f"Query: {query_info['query_text']}")
    print(f"Category: {query_info['category']} | Difficulty: {query_info['difficulty']}")
    print("\n" + "-"*80)
    print("TOP 5 K·∫æT QU·∫¢ T√åM KI·∫æM")
    print("-"*80)
    
    # T√≠nh relevance labels ƒë·ªÉ hi·ªÉn th·ªã
    if EVALUATION_METHOD == "distance":
        threshold = DISTANCE_THRESHOLD
        method_desc = f"distance < {threshold}"
    else:
        threshold = RELEVANCE_THRESHOLD
        method_desc = f"relevance >= {threshold}"
    
    print(f"\nüìä Ti√™u ch√≠ ƒë√°nh gi√°: {method_desc}")
    if EVALUATION_METHOD == "distance":
        print("   üí° Distance c√†ng NH·ªé ‚Üí c√†ng gi·ªëng ‚Üí c√†ng ƒê√öNG")
    else:
        print("   üí° Relevance score c√†ng CAO ‚Üí c√†ng ph√π h·ª£p ‚Üí c√†ng ƒê√öNG")
    print("\n" + "-"*80)
    
    for idx, result in enumerate(results, 1):
        person_id = result.get('person_id', 'N/A')
        distance = result.get('distance', None)
        title = result.get('title', 'N/A')
        skills = result.get('skills', 'N/A')
        abilities = result.get('abilities', 'N/A')
        program = result.get('program', 'N/A')
        
        # X√°c ƒë·ªãnh xem k·∫øt qu·∫£ c√≥ ƒë√∫ng/kh·ªõp kh√¥ng
        is_relevant = False
        if EVALUATION_METHOD == "distance":
            if distance is not None:
                is_relevant = distance < threshold
        else:
            if query_text:
                score = calculate_relevance_score(query_text, result)
                is_relevant = score >= threshold
        
        # ƒê√°nh d·∫•u r√µ r√†ng
        status_icon = "‚úì ƒê√öNG/KH·ªöP" if is_relevant else "‚úó KH√îNG KH·ªöP"
        status_color = "‚úì" if is_relevant else "‚úó"
        
        print(f"\n{'='*80}")
        print(f"K·∫æT QU·∫¢ [{idx}/5] - {status_icon}")
        print(f"{'='*80}")
        print(f"Person ID: {person_id}")
        if distance is not None:
            relevance_info = f"Distance: {distance:.4f}"
            if EVALUATION_METHOD == "distance":
                relevance_info += f" {'‚úì' if is_relevant else '‚úó'} {'< ' if is_relevant else '‚â• '}{threshold}"
            else:
                if query_text:
                    score = calculate_relevance_score(query_text, result)
                    relevance_info += f" | Relevance: {score:.3f} {'‚úì' if is_relevant else '‚úó'} {'‚â• ' if is_relevant else '< '}{threshold}"
            print(f"{relevance_info}")
        print(f"\nüìã Title/Role:")
        print(f"   {title}")
        print(f"\nüõ†Ô∏è  Skills:")
        # Hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß skills, chia th√†nh nhi·ªÅu d√≤ng n·∫øu qu√° d√†i
        if skills and skills != 'N/A':
            # Chia th√†nh c√°c d√≤ng 80 k√Ω t·ª±
            words = skills.split(', ')
            line = ""
            for word in words:
                if len(line) + len(word) + 2 > 75:
                    if line:
                        print(f"   {line.strip()}")
                    line = word + ", "
                else:
                    line += word + ", "
            if line:
                print(f"   {line.rstrip(', ')}")
        else:
            print(f"   {skills}")
        print(f"\nüíº Abilities:")
        if abilities and abilities != 'N/A':
            # Chia th√†nh c√°c d√≤ng 80 k√Ω t·ª±
            words = abilities.split(', ')
            line = ""
            for word in words:
                if len(line) + len(word) + 2 > 75:
                    if line:
                        print(f"   {line.strip()}")
                    line = word + ", "
                else:
                    line += word + ", "
            if line:
                print(f"   {line.rstrip(', ')}")
        else:
            print(f"   {abilities}")
        print(f"\nüéì Education/Program:")
        print(f"   {program}")
    
    print("\n" + "="*80)


# ============================================================================
# H√ÄM X·ª¨ L√ù TEXT V√Ä T√çNH RELEVANCE
# ============================================================================

def extract_keywords(text: str) -> set:
    """
    Tr√≠ch xu·∫•t t·ª´ kh√≥a t·ª´ text, b·ªè qua c√°c t·ª´ kh√¥ng quan tr·ªçng.
    
    V√≠ d·ª•: "Looking for a Python developer" ‚Üí {"looking", "python", "developer"}
    """
    # T√°ch text th√†nh c√°c t·ª´
    words = re.findall(r'\b\w+\b', text.lower())
    
    # Lo·∫°i b·ªè c√°c t·ª´ kh√¥ng quan tr·ªçng (t·ª´ ng·∫Øn v√† t·ª´ th∆∞·ªùng g·∫∑p)
    stop_words = {'the', 'for', 'and', 'with', 'in', 'on', 'at', 'to', 'a', 'an', 
                  'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 
                  'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 
                  'may', 'might', 'must', 'can', 'of', 'from', 'by', 'as', 'or', 
                  'but', 'not', 'this', 'that', 'these', 'those'}
    
    # Ch·ªâ gi·ªØ l·∫°i t·ª´ c√≥ √Ω nghƒ©a (d√†i h∆°n 2 k√Ω t·ª± v√† kh√¥ng ph·∫£i stop word)
    keywords = {w for w in words if len(w) >= 3 and w not in stop_words}
    return keywords


def calculate_relevance_score(query: str, result: Dict[str, Any]) -> float:
    """
    T√≠nh ƒëi·ªÉm ph√π h·ª£p (0-1) c·ªßa m·ªôt k·∫øt qu·∫£ v·ªõi query.
    
    ƒêi·ªÉm ƒë∆∞·ª£c t√≠nh t·ª´ 4 y·∫øu t·ªë:
    - 40%: ƒê·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a (distance) - ƒë√°nh gi√° b·∫±ng embedding
    - 20%: T·ª´ kh√≥a kh·ªõp trong ch·ª©c danh (title)
    - 25%: T·ª´ kh√≥a kh·ªõp trong k·ªπ nƒÉng (skills) - quan tr·ªçng nh·∫•t
    - 15%: T·ª´ kh√≥a kh·ªõp trong kh·∫£ nƒÉng (abilities)
    
    V√≠ d·ª•: Query "Python developer" v·ªõi h·ªì s∆° c√≥ skills "Python, Django"
    ‚Üí Skills match cao ‚Üí ƒëi·ªÉm relevance cao
    """
    score = 0.0
    
    # Ph·∫ßn 1: ƒêi·ªÉm t·ª´ ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a (40%)
    # Distance l√† kho·∫£ng c√°ch gi·ªØa vector query v√† vector h·ªì s∆°
    # Distance th∆∞·ªùng trong kho·∫£ng 0-2:
    #   - 0 = gi·ªëng ho√†n to√†n
    #   - 2 = kh√°c bi·ªát ho√†n to√†n
    distance = result.get('distance')
    if distance is not None:
        # Chuy·ªÉn distance (0-2) th√†nh ƒëi·ªÉm (1-0)
        # distance = 0 ‚Üí score = 1 (gi·ªëng ho√†n to√†n)
        # distance = 1 ‚Üí score = 0.5 (gi·ªëng m·ªôt n·ª≠a)
        # distance = 2 ‚Üí score = 0 (kh√°c bi·ªát ho√†n to√†n)
        distance_score = max(0, 1 - (distance / 2.0))
        score += distance_score * 0.4  # Chi·∫øm 40% t·ªïng ƒëi·ªÉm
    
    # Ph·∫ßn 2-4: ƒêi·ªÉm t·ª´ t·ª´ kh√≥a kh·ªõp (60% c√≤n l·∫°i)
    # Tr√≠ch xu·∫•t t·ª´ kh√≥a t·ª´ query (b·ªè qua c√°c t·ª´ kh√¥ng quan tr·ªçng nh∆∞ "the", "a", "for")
    query_keywords = extract_keywords(query)
    # V√≠ d·ª•: "Looking for a Python developer" ‚Üí {"looking", "python", "developer"}
    
    # So kh·ªõp trong ch·ª©c danh (20%)
    # V√≠ d·ª•: Query c√≥ "developer" v√† h·ªì s∆° c√≥ title "Senior Developer" ‚Üí kh·ªõp
    title = result.get('title', '').lower()
    title_keywords = extract_keywords(title)
    # T√≠nh t·ª∑ l·ªá: s·ªë t·ª´ kh√≥a chung / t·ªïng s·ªë t·ª´ kh√≥a trong query
    # V√≠ d·ª•: query c√≥ 3 t·ª´ kh√≥a, title c√≥ 1 t·ª´ kh√≥a chung ‚Üí match = 1/3 = 0.33
    title_match = len(query_keywords & title_keywords) / max(len(query_keywords), 1)
    score += title_match * 0.2
    
    # So kh·ªõp trong k·ªπ nƒÉng (25% - quan tr·ªçng nh·∫•t)
    # V√≠ d·ª•: Query c√≥ "Python" v√† h·ªì s∆° c√≥ skills "Python, Django, SQL" ‚Üí kh·ªõp
    skills = result.get('skills', '').lower()
    skills_keywords = extract_keywords(skills)
    skills_match = len(query_keywords & skills_keywords) / max(len(query_keywords), 1)
    score += skills_match * 0.25  # Chi·∫øm 25% - quan tr·ªçng nh·∫•t v√¨ skills l√† y√™u c·∫ßu ch√≠nh
    
    # So kh·ªõp trong kh·∫£ nƒÉng (15%)
    # V√≠ d·ª•: Query c√≥ "leadership" v√† h·ªì s∆° c√≥ abilities "leadership, communication" ‚Üí kh·ªõp
    abilities = result.get('abilities', '').lower()
    abilities_keywords = extract_keywords(abilities)
    abilities_match = len(query_keywords & abilities_keywords) / max(len(query_keywords), 1)
    score += abilities_match * 0.15
    
    # ƒê·∫£m b·∫£o ƒëi·ªÉm kh√¥ng v∆∞·ª£t qu√° 1.0 (t·ªëi ƒëa 100%)
    return min(1.0, score)


# ============================================================================
# H√ÄM T√çNH METRICS ƒê√ÅNH GI√Å
# ============================================================================

def get_relevance_labels(results: List[Dict[str, Any]], query: str, 
                         method: str = "distance", threshold: float = 0.8) -> List[int]:
    """
    X√°c ƒë·ªãnh k·∫øt qu·∫£ n√†o ph√π h·ª£p (1) v√† kh√¥ng ph√π h·ª£p (0).
    
    C√≥ 2 ph∆∞∆°ng ph√°p ƒë√°nh gi√°:
    
    1. "distance" (m·∫∑c ƒë·ªãnh):
       - Ch·ªâ d·ª±a v√†o ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a (embedding)
       - N·∫øu distance < threshold ‚Üí ph√π h·ª£p (1)
       - V√≠ d·ª•: threshold = 0.8, distance = 0.6 ‚Üí ph√π h·ª£p (0.6 < 0.8)
       - ∆Øu ƒëi·ªÉm: Nhanh, ƒë∆°n gi·∫£n
       - Nh∆∞·ª£c ƒëi·ªÉm: C√≥ th·ªÉ b·ªè s√≥t k·∫øt qu·∫£ ph√π h·ª£p v·ªÅ t·ª´ kh√≥a nh∆∞ng kh√°c v·ªÅ ng·ªØ nghƒ©a
    
    2. "relevance":
       - K·∫øt h·ª£p distance (40%) + keyword matching (60%)
       - N·∫øu relevance score >= threshold ‚Üí ph√π h·ª£p (1)
       - V√≠ d·ª•: threshold = 0.5, score = 0.7 ‚Üí ph√π h·ª£p (0.7 >= 0.5)
       - ∆Øu ƒëi·ªÉm: Ch√≠nh x√°c h∆°n, xem x√©t c·∫£ t·ª´ kh√≥a
       - Nh∆∞·ª£c ƒëi·ªÉm: Ch·∫≠m h∆°n v√¨ ph·∫£i t√≠nh relevance score
    
    Returns:
        List nh√£n binary [0, 1, 0, 1, ...] t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng k·∫øt qu·∫£
        - 1 = ph√π h·ª£p (relevant)
        - 0 = kh√¥ng ph√π h·ª£p (non-relevant)
    """
    labels = []
    
    # Duy·ªát qua t·ª´ng k·∫øt qu·∫£ t√¨m ki·∫øm
    for result in results:
        is_relevant = False
        
        if method == "distance":
            # Ph∆∞∆°ng ph√°p 1: Ch·ªâ d√πng distance
            # Distance l√† kho·∫£ng c√°ch gi·ªØa vector query v√† vector h·ªì s∆°
            # Distance c√†ng nh·ªè = c√†ng gi·ªëng nhau v·ªÅ m·∫∑t ng·ªØ nghƒ©a = c√†ng ph√π h·ª£p
            distance = result.get('distance')
            if distance is not None:
                # N·∫øu distance nh·ªè h∆°n ng∆∞·ª°ng ‚Üí k·∫øt qu·∫£ n√†y ph√π h·ª£p
                # V√≠ d·ª•: threshold = 0.8, distance = 0.6 ‚Üí 0.6 < 0.8 ‚Üí ph√π h·ª£p
                is_relevant = distance < threshold
                
        elif method == "relevance":
            # Ph∆∞∆°ng ph√°p 2: D√πng relevance score (k·∫øt h·ª£p distance + keywords)
            # Relevance score ƒë∆∞·ª£c t√≠nh t·ª´:
            # - 40% distance (ƒë·ªô t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a)
            # - 60% keyword matching (t·ª´ kh√≥a kh·ªõp trong title, skills, abilities)
            score = calculate_relevance_score(query, result)
            # N·∫øu score l·ªõn h∆°n ho·∫∑c b·∫±ng ng∆∞·ª°ng ‚Üí k·∫øt qu·∫£ n√†y ph√π h·ª£p
            # V√≠ d·ª•: threshold = 0.5, score = 0.7 ‚Üí 0.7 >= 0.5 ‚Üí ph√π h·ª£p
            is_relevant = score >= threshold
        
        # Chuy·ªÉn ƒë·ªïi th√†nh nh√£n binary: 1 = ph√π h·ª£p, 0 = kh√¥ng ph√π h·ª£p
        labels.append(1 if is_relevant else 0)
    
    return labels


def precision_at_k(relevance_labels: List[int], k: int) -> float:
    """
    T√≠nh Precision@K - T·ª∑ l·ªá k·∫øt qu·∫£ ph√π h·ª£p trong top K.
    
    C√¥ng th·ª©c: Precision@K = (S·ªë k·∫øt qu·∫£ ph√π h·ª£p trong top K) / K
    
    V√≠ d·ª•: 
    - labels = [1, 1, 0, 1, 0] (5 k·∫øt qu·∫£, 3 ph√π h·ª£p)
    - Precision@5 = 3/5 = 0.6 (60% k·∫øt qu·∫£ ph√π h·ª£p)
    - Precision@5 = 1.0 nghƒ©a l√† t·∫•t c·∫£ 5 k·∫øt qu·∫£ ƒë·ªÅu ph√π h·ª£p (ho√†n h·∫£o)
    
    Precision@K c√†ng cao ‚Üí h·ªá th·ªëng c√†ng ch√≠nh x√°c
    """
    if k == 0:
        return 0.0
    
    # L·∫•y k nh√£n ƒë·∫ßu ti√™n (top K k·∫øt qu·∫£)
    top_k_labels = relevance_labels[:k]
    if not top_k_labels:
        return 0.0
    
    # ƒê·∫øm s·ªë k·∫øt qu·∫£ ph√π h·ª£p (nh√£n = 1)
    # V√≠ d·ª•: [1, 1, 0, 1, 0] ‚Üí sum = 3
    relevant_count = sum(top_k_labels)
    
    # T√≠nh t·ª∑ l·ªá: s·ªë ph√π h·ª£p / t·ªïng s·ªë k·∫øt qu·∫£
    return relevant_count / len(top_k_labels)


def average_precision_at_k(relevance_labels: List[int], k: int) -> float:
    """
    T√≠nh AP@K (Average Precision@K) - ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng th·ª© t·ª± s·∫Øp x·∫øp.
    
    AP@K kh√°c v·ªõi Precision@K ·ªü ch·ªó:
    - Precision@K: Ch·ªâ quan t√¢m c√≥ bao nhi√™u k·∫øt qu·∫£ ph√π h·ª£p
    - AP@K: Quan t√¢m c·∫£ v·ªã tr√≠ c·ªßa c√°c k·∫øt qu·∫£ ph√π h·ª£p
    
    N·∫øu k·∫øt qu·∫£ ph√π h·ª£p ƒë∆∞·ª£c x·∫øp ·ªü v·ªã tr√≠ cao (1, 2, 3) ‚Üí AP@K cao
    N·∫øu k·∫øt qu·∫£ ph√π h·ª£p b·ªã x·∫øp ·ªü v·ªã tr√≠ th·∫•p (4, 5) ‚Üí AP@K th·∫•p
    
    C√¥ng th·ª©c: AP@K = (1/R) * Œ£(P@i cho m·ªói v·ªã tr√≠ i c√≥ k·∫øt qu·∫£ ph√π h·ª£p)
    R = t·ªïng s·ªë k·∫øt qu·∫£ ph√π h·ª£p trong top K
    
    V√≠ d·ª• chi ti·∫øt v·ªõi labels = [1, 1, 0, 1, 0]:
    - V·ªã tr√≠ 1: ph√π h·ª£p (1) ‚Üí P@1 = 1/1 = 1.0 (c√≥ 1 ph√π h·ª£p trong 1 k·∫øt qu·∫£ ƒë·∫ßu)
    - V·ªã tr√≠ 2: ph√π h·ª£p (1) ‚Üí P@2 = 2/2 = 1.0 (c√≥ 2 ph√π h·ª£p trong 2 k·∫øt qu·∫£ ƒë·∫ßu)
    - V·ªã tr√≠ 3: kh√¥ng ph√π h·ª£p (0) ‚Üí b·ªè qua
    - V·ªã tr√≠ 4: ph√π h·ª£p (1) ‚Üí P@4 = 3/4 = 0.75 (c√≥ 3 ph√π h·ª£p trong 4 k·∫øt qu·∫£ ƒë·∫ßu)
    - V·ªã tr√≠ 5: kh√¥ng ph√π h·ª£p (0) ‚Üí b·ªè qua
    
    AP@5 = (1.0 + 1.0 + 0.75) / 3 = 0.917
    ‚Üí ƒêi·ªÉm cao v√¨ c√°c k·∫øt qu·∫£ ph√π h·ª£p ƒë∆∞·ª£c x·∫øp ·ªü v·ªã tr√≠ cao
    """
    if k == 0:
        return 0.0
    
    top_k_labels = relevance_labels[:k]
    if not top_k_labels:
        return 0.0
    
    # ƒê·∫øm t·ªïng s·ªë k·∫øt qu·∫£ ph√π h·ª£p trong top K
    total_relevant = sum(top_k_labels)
    if total_relevant == 0:
        return 0.0  # Kh√¥ng c√≥ k·∫øt qu·∫£ ph√π h·ª£p n√†o ‚Üí AP@K = 0
    
    # T√≠nh precision t·∫°i m·ªói v·ªã tr√≠ c√≥ k·∫øt qu·∫£ ph√π h·ª£p
    ap_sum = 0.0
    relevant_found = 0  # S·ªë l∆∞·ª£ng k·∫øt qu·∫£ ph√π h·ª£p ƒë√£ t√¨m th·∫•y t·ª´ ƒë·∫ßu ƒë·∫øn v·ªã tr√≠ hi·ªán t·∫°i
    
    # Duy·ªát qua t·ª´ng v·ªã tr√≠ trong top K
    for i, label in enumerate(top_k_labels, 1):  # i b·∫Øt ƒë·∫ßu t·ª´ 1 (v·ªã tr√≠ 1, 2, 3, ...)
        if label == 1:  # N·∫øu k·∫øt qu·∫£ ·ªü v·ªã tr√≠ i l√† ph√π h·ª£p
            relevant_found += 1  # TƒÉng s·ªë l∆∞·ª£ng ph√π h·ª£p ƒë√£ t√¨m th·∫•y
            # T√≠nh precision t·∫°i v·ªã tr√≠ i
            # Precision@i = s·ªë ph√π h·ª£p t·ª´ ƒë·∫ßu ƒë·∫øn v·ªã tr√≠ i / v·ªã tr√≠ i
            precision_at_i = relevant_found / i
            ap_sum += precision_at_i  # C·ªông d·ªìn v√†o t·ªïng
    
    # Trung b√¨nh: t·ªïng precision / s·ªë l∆∞·ª£ng k·∫øt qu·∫£ ph√π h·ª£p
    return ap_sum / total_relevant


def calculate_metrics(results: List[Dict[str, Any]], query: str,
                     k: int = 5, method: str = "distance", threshold: float = 0.8) -> Dict[str, float]:
    """
    T√≠nh c√°c ch·ªâ s·ªë ƒë√°nh gi√°: Precision@K v√† AP@K.
    
    Quy tr√¨nh:
    1. X√°c ƒë·ªãnh k·∫øt qu·∫£ n√†o ph√π h·ª£p (relevant) v√† kh√¥ng ph√π h·ª£p (non-relevant)
    2. T√≠nh Precision@K: T·ª∑ l·ªá k·∫øt qu·∫£ ph√π h·ª£p trong top K
    3. T√≠nh AP@K: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng th·ª© t·ª± s·∫Øp x·∫øp
    
    Args:
        results: Danh s√°ch 5 k·∫øt qu·∫£ t√¨m ki·∫øm
        query: C√¢u truy v·∫•n
        k: S·ªë k·∫øt qu·∫£ ƒë·∫ßu ti√™n (th∆∞·ªùng l√† 5)
        method: "distance" ho·∫∑c "relevance"
        threshold: Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh ph√π h·ª£p
    
    Returns:
        Dictionary ch·ª©a:
        - precision_at_k: Precision@K (0.0 - 1.0)
        - ap_at_k: Average Precision@K (0.0 - 1.0)
        - relevance_labels: [0, 1, 0, 1, ...] - nh√£n c·ªßa t·ª´ng k·∫øt qu·∫£
        - num_relevant: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ ph√π h·ª£p (0-5)
    """
    # B∆∞·ªõc 1: X√°c ƒë·ªãnh k·∫øt qu·∫£ n√†o ph√π h·ª£p
    # Chuy·ªÉn ƒë·ªïi m·ªói k·∫øt qu·∫£ th√†nh nh√£n binary: 1 = ph√π h·ª£p, 0 = kh√¥ng ph√π h·ª£p
    # V√≠ d·ª•: [1, 1, 0, 1, 0] nghƒ©a l√† k·∫øt qu·∫£ 1, 2, 4 ph√π h·ª£p; k·∫øt qu·∫£ 3, 5 kh√¥ng ph√π h·ª£p
    relevance_labels = get_relevance_labels(results, query, method, threshold)
    
    # B∆∞·ªõc 2: T√≠nh Precision@K
    # Precision@K = s·ªë k·∫øt qu·∫£ ph√π h·ª£p / t·ªïng s·ªë k·∫øt qu·∫£
    # V√≠ d·ª•: [1, 1, 0, 1, 0] ‚Üí 3 ph√π h·ª£p / 5 t·ªïng = 0.6
    p_at_k = precision_at_k(relevance_labels, k)
    
    # B∆∞·ªõc 3: T√≠nh AP@K
    # AP@K ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng th·ª© t·ª±: k·∫øt qu·∫£ ph√π h·ª£p ·ªü v·ªã tr√≠ cao ‚Üí AP@K cao
    # V√≠ d·ª•: [1, 1, 0, 1, 0] ‚Üí AP@5 = 0.917 (c√°c k·∫øt qu·∫£ ph√π h·ª£p ·ªü v·ªã tr√≠ 1, 2, 4)
    ap_at_k = average_precision_at_k(relevance_labels, k)
    
    return {
        'precision_at_k': p_at_k,              # Precision@K
        'ap_at_k': ap_at_k,                    # Average Precision@K
        'relevance_labels': relevance_labels,   # Nh√£n binary [0, 1, 0, 1, ...]
        'num_relevant': sum(relevance_labels)  # S·ªë l∆∞·ª£ng k·∫øt qu·∫£ ph√π h·ª£p
    }


def auto_evaluate_results(query: str, results: List[Dict[str, Any]], method: str = "combined", threshold: float = 0.5) -> int:
    """
    T·ª± ƒë·ªông ƒë√°nh gi√° s·ªë k·∫øt qu·∫£ ph√π h·ª£p.
    
    Args:
        query: Query text
        results: List of search results
        method: "distance", "keywords", ho·∫∑c "combined"
        threshold: Ng∆∞·ª°ng ƒë·ªÉ coi l√† ph√π h·ª£p (0-1)
    
    Returns:
        S·ªë k·∫øt qu·∫£ ƒë∆∞·ª£c ƒë√°nh gi√° l√† ph√π h·ª£p (0-5)
    """
    correct_count = 0
    
    for result in results:
        is_relevant = False
        
        if method == "distance":
            # Ch·ªâ d·ª±a tr√™n distance
            distance = result.get('distance')
            if distance is not None:
                # Distance < threshold * 2 (v√¨ distance th∆∞·ªùng 0-2)
                is_relevant = distance < (threshold * 2)
        
        elif method == "keywords":
            # Ch·ªâ d·ª±a tr√™n keyword matching
            score = calculate_relevance_score(query, result)
            is_relevant = score >= threshold
        
        elif method == "combined":
            # K·∫øt h·ª£p distance v√† keywords
            score = calculate_relevance_score(query, result)
            is_relevant = score >= threshold
        
        if is_relevant:
            correct_count += 1
    
    return correct_count


def get_correct_count(query: str, results: List[Dict[str, Any]], auto_mode: bool = False) -> int:
    """
    ƒê√°nh gi√° s·ªë c√¢u tr·∫£ l·ªùi ƒë√∫ng.
    N·∫øu auto_mode=True, t·ª± ƒë·ªông ƒë√°nh gi√°. N·∫øu False, y√™u c·∫ßu ng∆∞·ªùi d√πng nh·∫≠p.
    """
    if auto_mode:
        # T·ª± ƒë·ªông ƒë√°nh gi√°
        print("\n" + "="*80)
        print("ƒê√ÅNH GI√Å T·ª∞ ƒê·ªòNG")
        print("="*80)
        
        if EVALUATION_METHOD == "distance":
            print(f"ƒêang ƒë√°nh gi√° t·ª± ƒë·ªông d·ª±a tr√™n DISTANCE (distance < {DISTANCE_THRESHOLD} ‚Üí relevant)")
            print("  üí° Distance c√†ng NH·ªé ‚Üí c√†ng gi·ªëng ‚Üí c√†ng ƒë√∫ng")
            print("\nDistance c·ªßa t·ª´ng k·∫øt qu·∫£:")
            for idx, result in enumerate(results, 1):
                distance = result.get('distance', 'N/A')
                person_id = result.get('person_id', 'N/A')
                is_relevant = distance != 'N/A' and distance < DISTANCE_THRESHOLD
                status = "‚úì RELEVANT" if is_relevant else "‚úó Non-relevant"
                print(f"  [{idx}] Person ID: {person_id} | Distance: {distance:.4f} {status}")
            
            # ƒê·∫øm s·ªë relevant
            correct_count = sum(1 for r in results 
                              if r.get('distance') is not None and r.get('distance') < DISTANCE_THRESHOLD)
            print(f"\n‚úì T·ª± ƒë·ªông ƒë√°nh gi√°: {correct_count}/5 k·∫øt qu·∫£ ph√π h·ª£p (distance < {DISTANCE_THRESHOLD})")
        else:
            print(f"ƒêang ƒë√°nh gi√° t·ª± ƒë·ªông d·ª±a tr√™n RELEVANCE SCORE (score >= {RELEVANCE_THRESHOLD} ‚Üí relevant)")
            print("  üí° Relevance score c√†ng CAO ‚Üí c√†ng ph√π h·ª£p ‚Üí c√†ng ƒë√∫ng")
            print("\nRelevance score c·ªßa t·ª´ng k·∫øt qu·∫£:")
            for idx, result in enumerate(results, 1):
                score = calculate_relevance_score(query, result)
                distance = result.get('distance', 'N/A')
                person_id = result.get('person_id', 'N/A')
                is_relevant = score >= RELEVANCE_THRESHOLD
                status = "‚úì RELEVANT" if is_relevant else "‚úó Non-relevant"
                print(f"  [{idx}] Person ID: {person_id} | Distance: {distance:.4f} | Relevance: {score:.3f} {status}")
            
            # ƒê·∫øm s·ªë relevant
            correct_count = sum(1 for r in results 
                              if calculate_relevance_score(query, r) >= RELEVANCE_THRESHOLD)
            print(f"\n‚úì T·ª± ƒë·ªông ƒë√°nh gi√°: {correct_count}/5 k·∫øt qu·∫£ ph√π h·ª£p (relevance >= {RELEVANCE_THRESHOLD})")
        
        # Cho ph√©p ng∆∞·ªùi d√πng x√°c nh·∫≠n ho·∫∑c ch·ªânh s·ª≠a
        print("\nB·∫°n c√≥ mu·ªën ch·ªânh s·ª≠a k·∫øt qu·∫£ n√†y kh√¥ng? (Enter ƒë·ªÉ ch·∫•p nh·∫≠n, ho·∫∑c nh·∫≠p s·ªë 0-5):")
        user_input = input(">>> ").strip()
        
        if user_input.lower() in ['exit', 'quit', 'q']:
            return -1
        elif user_input == "":
            return correct_count
        else:
            try:
                count = int(user_input)
                if 0 <= count <= 5:
                    return count
                else:
                    print("‚ö†Ô∏è  S·ªë kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng k·∫øt qu·∫£ t·ª± ƒë·ªông.")
                    return correct_count
            except ValueError:
                print("‚ö†Ô∏è  Kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng k·∫øt qu·∫£ t·ª± ƒë·ªông.")
                return correct_count
    else:
        # ƒê√°nh gi√° th·ªß c√¥ng
        print("\n" + "="*80)
        print("ƒê√ÅNH GI√Å K·∫æT QU·∫¢")
        print("="*80)
        print("D·ª±a tr√™n c√°c ti√™u ch√≠ ƒë√£ g·ª£i √Ω ·ªü tr√™n, h√£y ƒë·∫øm s·ªë k·∫øt qu·∫£ PH√ô H·ª¢P v·ªõi query.")
        print("M·ªôt k·∫øt qu·∫£ ƒë∆∞·ª£c coi l√† PH√ô H·ª¢P n·∫øu:")
        print("  ‚úì C√≥ c√°c k·ªπ nƒÉng/c√¥ng ngh·ªá ƒë∆∞·ª£c y√™u c·∫ßu trong query")
        print("  ‚úì Ch·ª©c danh/vai tr√≤ ph√π h·ª£p v·ªõi y√™u c·∫ßu")
        print("  ‚úì B·∫±ng c·∫•p/gi√°o d·ª•c ph√π h·ª£p (n·∫øu query y√™u c·∫ßu)")
        print("  ‚úì C√≥ ƒë·ªô li√™n quan t·ªïng th·ªÉ t·ªët v·ªõi query")
        print("\nNh·∫≠p s·ªë k·∫øt qu·∫£ PH√ô H·ª¢P (0-5):")
        while True:
            try:
                count = input(">>> ").strip()
                if count.lower() in ['exit', 'quit', 'q']:
                    return -1  # Signal ƒë·ªÉ d·ª´ng
                count = int(count)
                if 0 <= count <= 5:
                    return count
                else:
                    print("‚ö†Ô∏è  Vui l√≤ng nh·∫≠p s·ªë t·ª´ 0 ƒë·∫øn 5!")
            except ValueError:
                print("‚ö†Ô∏è  Vui l√≤ng nh·∫≠p m·ªôt s·ªë h·ª£p l·ªá!")


# ============================================================================
# H√ÄM CH√çNH X·ª¨ L√ù QUERIES
# ============================================================================

def process_queries():
    """
    H√†m ch√≠nh x·ª≠ l√Ω t·∫•t c·∫£ queries.
    
    Quy tr√¨nh:
    1. ƒê·ªçc queries t·ª´ file
    2. T·∫£i ti·∫øn tr√¨nh ƒë√£ l∆∞u (n·∫øu c√≥)
    3. X·ª≠ l√Ω t·ª´ng query: t√¨m ki·∫øm ‚Üí t√≠nh metrics ‚Üí l∆∞u k·∫øt qu·∫£
    4. T√≠nh th·ªëng k√™ t·ªïng h·ª£p khi xong
    """
    # ƒê·ªçc queries
    print("ƒêang ƒë·ªçc queries t·ª´ file...")
    all_queries = load_queries()
    print(f"T·ªïng s·ªë queries: {len(all_queries)}")
    
    # T·∫£i ti·∫øn tr√¨nh ƒë√£ l∆∞u ƒë·ªÉ ti·∫øp t·ª•c
    progress = load_progress()
    start_index = progress["last_processed_index"]
    results = progress["results"]
    search_results_data = load_search_results()
    
    print(f"\nTi·∫øp t·ª•c t·ª´ query th·ª© {start_index + 1} (ƒë√£ x·ª≠ l√Ω {len(results)} queries)")
    
    # X√°c ƒë·ªãnh s·ªë queries c·∫ßn x·ª≠ l√Ω trong batch n√†y
    end_index = min(start_index + BATCH_SIZE, len(all_queries))
    queries_to_process = all_queries[start_index:end_index]
    
    print(f"S·∫Ω x·ª≠ l√Ω {len(queries_to_process)} queries (t·ª´ {start_index + 1} ƒë·∫øn {end_index})")
    print(f"B·∫°n c√≥ th·ªÉ nh·∫≠p 'exit' ho·∫∑c 'quit' b·∫•t c·ª© l√∫c n√†o ƒë·ªÉ d·ª´ng v√† l∆∞u progress\n")
    
    # X·ª≠ l√Ω t·ª´ng query trong batch
    for idx, query_info in enumerate(queries_to_process, start=start_index):
        # L·∫•y n·ªôi dung query (c√¢u truy v·∫•n)
        query_text = query_info["query_text"]
        
        # B·ªè qua n·∫øu query r·ªóng
        if not query_text.strip():
            print(f"\nQuery {idx + 1} b·ªè qua (query_text r·ªóng)")
            continue
        
        print(f"\n[{idx + 1}/{len(all_queries)}] ƒêang x·ª≠ l√Ω query...")
        
        # B∆∞·ªõc 1: T√¨m ki·∫øm top 5 h·ªì s∆° ph√π h·ª£p nh·∫•t
        # H√†m n√†y s·∫Ω:
        # - Chuy·ªÉn query th√†nh vector (embedding)
        # - So s√°nh v·ªõi t·∫•t c·∫£ h·ªì s∆° trong database
        # - Tr·∫£ v·ªÅ 5 h·ªì s∆° c√≥ distance nh·ªè nh·∫•t (gi·ªëng nh·∫•t)
        search_results = search_top5(query_text)
        
        # B∆∞·ªõc 2: L∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm v√†o file
        # L∆∞u ƒë·ªÉ c√≥ th·ªÉ ƒë√°nh gi√° l·∫°i sau n√†y ho·∫∑c ph√¢n t√≠ch
        search_result_entry = {
            "query_id": query_info["query_id"],           # ID c·ªßa query
            "query_text": query_text,                      # N·ªôi dung query
            "category": query_info["category"],            # Danh m·ª•c (BE, FE, PM, etc.)
            "target_person_id": query_info["target_person_id"],  # ID ng∆∞·ªùi m·ª•c ti√™u
            "difficulty": query_info["difficulty"],       # ƒê·ªô kh√≥ (standard, hard)
            "search_results": search_results,              # 5 k·∫øt qu·∫£ t√¨m ki·∫øm
            "timestamp": None
        }
        # Ki·ªÉm tra xem query n√†y ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ch∆∞a (tr√°nh tr√πng l·∫∑p khi ti·∫øp t·ª•c)
        existing_idx = next((i for i, item in enumerate(search_results_data) 
                            if item.get("query_id") == query_info["query_id"]), None)
        if existing_idx is not None:
            # N·∫øu ƒë√£ c√≥ ‚Üí c·∫≠p nh·∫≠t (tr∆∞·ªùng h·ª£p ch·∫°y l·∫°i)
            search_results_data[existing_idx] = search_result_entry
        else:
            # N·∫øu ch∆∞a c√≥ ‚Üí th√™m m·ªõi
            search_results_data.append(search_result_entry)
        save_search_results(search_results_data)
        
        # B∆∞·ªõc 3: T√≠nh metrics ƒë√°nh gi√°
        if not search_results:
            # N·∫øu kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o ‚Üí metrics = 0
            print("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o!")
            metrics = {
                'precision_at_k': 0.0,                    # Kh√¥ng c√≥ k·∫øt qu·∫£ ph√π h·ª£p
                'ap_at_k': 0.0,                          # Kh√¥ng c√≥ k·∫øt qu·∫£ ph√π h·ª£p
                'relevance_labels': [0, 0, 0, 0, 0],     # T·∫•t c·∫£ ƒë·ªÅu kh√¥ng ph√π h·ª£p
                'num_relevant': 0                        # 0 k·∫øt qu·∫£ ph√π h·ª£p
            }
        else:
            # Hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ki·∫øm cho ng∆∞·ªùi d√πng xem
            # Hi·ªÉn th·ªã th√¥ng tin query v√† 5 k·∫øt qu·∫£ v·ªõi ƒë√°nh gi√° ph√π h·ª£p/kh√¥ng ph√π h·ª£p
            display_results(search_results, query_info, query_text)
            
            # X√°c ƒë·ªãnh threshold v√† method d·ª±a tr√™n c·∫•u h√¨nh
            if EVALUATION_METHOD == "distance":
                # D√πng distance: distance < threshold ‚Üí ph√π h·ª£p
                threshold = DISTANCE_THRESHOLD
                method_desc = f"distance < {threshold}"
            else:
                # D√πng relevance score: score >= threshold ‚Üí ph√π h·ª£p
                threshold = RELEVANCE_THRESHOLD
                method_desc = f"relevance score >= {threshold}"
            
            # T√≠nh c√°c metrics ƒë√°nh gi√°
            # - Precision@5: T·ª∑ l·ªá k·∫øt qu·∫£ ph√π h·ª£p trong top 5
            # - AP@5: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng th·ª© t·ª± s·∫Øp x·∫øp
            metrics = calculate_metrics(
                search_results,              # 5 k·∫øt qu·∫£ t√¨m ki·∫øm
                query=query_text,            # Query ƒë·ªÉ t√≠nh relevance score (n·∫øu d√πng method="relevance")
                k=5,                        # ƒê√°nh gi√° top 5
                method=EVALUATION_METHOD,    # Ph∆∞∆°ng ph√°p ƒë√°nh gi√°: "distance" ho·∫∑c "relevance"
                threshold=threshold         # Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh ph√π h·ª£p
            )
            
            # Hi·ªÉn th·ªã metrics
            print("\n" + "="*80)
            print(f"METRICS ƒê√ÅNH GI√Å (d·ª±a tr√™n {EVALUATION_METHOD}, {method_desc})")
            print("="*80)
            print(f"Precision@5: {metrics['precision_at_k']:.4f} ({metrics['num_relevant']}/5 relevant)")
            print(f"AP@5 (Average Precision@5): {metrics['ap_at_k']:.4f}")
            print(f"Relevance labels: {metrics['relevance_labels']}")
            
            print(f"\nüí° C√ÅC METRICS ƒê∆Ø·ª¢C T√çNH D·ª∞A TR√äN:")
            print(f"   1. Precision@K: T·ª∑ l·ªá k·∫øt qu·∫£ relevant trong top K")
            print(f"   2. AP@K (Average Precision@K): Trung b√¨nh precision t·∫°i c√°c v·ªã tr√≠ c√≥ k·∫øt qu·∫£ relevant")
            print(f"   3. MAP@K (Mean Average Precision@K): Trung b√¨nh c·ªßa t·∫•t c·∫£ AP@K qua t·∫•t c·∫£ queries")
            print(f"   (MAP@K s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã khi ho√†n th√†nh t·∫•t c·∫£ queries)")
            
            if EVALUATION_METHOD == "distance":
                print(f"\nüìä Ti√™u ch√≠ x√°c ƒë·ªãnh relevant: distance < {DISTANCE_THRESHOLD}")
                print(f"   (Distance c√†ng nh·ªè ‚Üí c√†ng gi·ªëng ‚Üí c√†ng ƒë√∫ng)")
            else:
                print(f"\nüìä Ti√™u ch√≠ x√°c ƒë·ªãnh relevant: relevance score >= {RELEVANCE_THRESHOLD}")
                print(f"   (Relevance score = distance 40% + keyword matching 60%)")
            
            # ƒê√°nh gi√° (t·ª± ƒë·ªông ho·∫∑c th·ªß c√¥ng) - gi·ªØ l·∫°i ƒë·ªÉ t∆∞∆°ng th√≠ch (kh√¥ng d√πng cho metrics)
            correct_count = get_correct_count(query_text, search_results, auto_mode=AUTO_EVALUATION)
            
            if correct_count == -1:
                print("\nƒê√£ d·ª´ng. ƒêang l∆∞u progress...")
                progress["last_processed_index"] = idx
                progress["results"] = results
                save_progress(progress)
                print(f"ƒê√£ l∆∞u progress. ƒê√£ x·ª≠ l√Ω {len(results)} queries.")
                print(f"ƒê√£ l∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm v√†o: {SEARCH_RESULTS_FILE}")
                return
        
        # L∆∞u k·∫øt qu·∫£ (ch·ªâ d√πng metrics, kh√¥ng d√πng accuracy)
        result_entry = {
            "query_id": query_info["query_id"],
            "query_text": query_text,
            "category": query_info["category"],
            "target_person_id": query_info["target_person_id"],
            "difficulty": query_info["difficulty"],
            "precision_at_5": metrics['precision_at_k'],
            "ap_at_5": metrics['ap_at_k'],
            "relevance_labels": metrics['relevance_labels'],
            "num_relevant": metrics['num_relevant'],
            "search_results": search_results
        }
        results.append(result_entry)
        
        # L∆∞u progress sau m·ªói query
        progress["last_processed_index"] = idx + 1
        progress["results"] = results
        save_progress(progress)
        
        print(f"‚úì ƒê√£ l∆∞u. Precision@5: {metrics['precision_at_k']:.4f} ({metrics['num_relevant']}/5)")
        print(f"‚úì ƒê√£ l∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm v√†o file: {SEARCH_RESULTS_FILE.name}")
    
    # Ki·ªÉm tra xem ƒë√£ x·ª≠ l√Ω h·∫øt ch∆∞a
    if end_index >= len(all_queries):
        print("\n" + "="*80)
        print("ƒê√É X·ª¨ L√ù H·∫æT T·∫§T C·∫¢ QUERIES!")
        print("="*80)
        
        # T√≠nh th·ªëng k√™ t·ªïng h·ª£p
        total = len(results)
        if total > 0:
            # T√≠nh MAP@5 (trung b√¨nh AP@5 c·ªßa t·∫•t c·∫£ queries)
            ap_scores = [r.get("ap_at_5", 0.0) for r in results]
            map_at_5 = sum(ap_scores) / total if total > 0 else 0.0
            
            # T√≠nh Precision@5 trung b√¨nh
            precision_scores = [r.get("precision_at_5", 0.0) for r in results]
            avg_precision_at_5 = sum(precision_scores) / total if total > 0 else 0.0
            
            # Ph√¢n t√≠ch ph√¢n ph·ªëi Precision@5
            precision_sorted = sorted(precision_scores)
            min_precision = min(precision_scores)
            max_precision = max(precision_scores)
            median_precision = precision_sorted[total // 2] if total > 0 else 0.0
            
            # ƒê·∫øm s·ªë queries theo m·ª©c Precision@5
            perfect_queries = sum(1 for p in precision_scores if p == 1.0)
            high_queries = sum(1 for p in precision_scores if 0.8 <= p < 1.0)
            medium_queries = sum(1 for p in precision_scores if 0.5 <= p < 0.8)
            low_queries = sum(1 for p in precision_scores if p < 0.5)
            
            # Ph√¢n t√≠ch ph√¢n ph·ªëi AP@5
            ap_sorted = sorted(ap_scores)
            min_ap = min(ap_scores)
            max_ap = max(ap_scores)
            median_ap = ap_sorted[total // 2] if total > 0 else 0.0
            
            # Ph√¢n t√≠ch s·ªë l∆∞·ª£ng relevant results
            all_num_relevant = [r.get("num_relevant", 0) for r in results]
            avg_relevant = sum(all_num_relevant) / total if total > 0 else 0.0
            total_relevant_all = sum(all_num_relevant)
            max_possible = total * 5  # M·ªói query c√≥ 5 k·∫øt qu·∫£
            
            # Ph√¢n t√≠ch distance (n·∫øu c√≥)
            all_distances = []
            for r in results:
                for sr in r.get("search_results", []):
                    dist = sr.get("distance")
                    if dist is not None:
                        all_distances.append(dist)
            
            print(f"\nT·ªïng s·ªë queries ƒë√£ x·ª≠ l√Ω: {total}")
            print(f"\n{'='*80}")
            print("METRICS T·ªîNG K·∫æT")
            print(f"{'='*80}")
            print(f"Precision@5 trung b√¨nh: {avg_precision_at_5:.4f}")
            print(f"MAP@5 (Mean Average Precision@5): {map_at_5:.4f}")
            
            print(f"\n{'='*80}")
            print("PH√ÇN T√çCH CHI TI·∫æT PRECISION@5")
            print(f"{'='*80}")
            print(f"Min: {min_precision:.4f} | Max: {max_precision:.4f} | Median: {median_precision:.4f}")
            print(f"\nPh√¢n b·ªë Precision@5:")
            print(f"  Perfect (1.0000): {perfect_queries} queries ({perfect_queries/total*100:.1f}%)")
            print(f"  High (0.80-0.99): {high_queries} queries ({high_queries/total*100:.1f}%)")
            print(f"  Medium (0.50-0.79): {medium_queries} queries ({medium_queries/total*100:.1f}%)")
            print(f"  Low (<0.50): {low_queries} queries ({low_queries/total*100:.1f}%)")
            
            print(f"\n{'='*80}")
            print("PH√ÇN T√çCH CHI TI·∫æT AP@5")
            print(f"{'='*80}")
            print(f"Min: {min_ap:.4f} | Max: {max_ap:.4f} | Median: {median_ap:.4f}")
            
            print(f"\n{'='*80}")
            print("PH√ÇN T√çCH S·ªê L∆Ø·ª¢NG RELEVANT RESULTS")
            print(f"{'='*80}")
            print(f"T·ªïng s·ªë k·∫øt qu·∫£ relevant: {total_relevant_all}/{max_possible}")
            print(f"T·ª∑ l·ªá relevant: {total_relevant_all/max_possible*100:.2f}%")
            print(f"S·ªë l∆∞·ª£ng relevant trung b√¨nh m·ªói query: {avg_relevant:.2f}/5")
            
            if all_distances:
                avg_distance = sum(all_distances) / len(all_distances)
                min_distance = min(all_distances)
                max_distance = max(all_distances)
                distance_sorted = sorted(all_distances)
                median_distance = distance_sorted[len(distance_sorted) // 2]
                
                print(f"\n{'='*80}")
                print("PH√ÇN T√çCH DISTANCE")
                print(f"{'='*80}")
                print(f"Distance trung b√¨nh: {avg_distance:.4f}")
                print(f"Min: {min_distance:.4f} | Max: {max_distance:.4f} | Median: {median_distance:.4f}")
                if EVALUATION_METHOD == "distance":
                    relevant_distances = [d for d in all_distances if d < DISTANCE_THRESHOLD]
                    non_relevant_distances = [d for d in all_distances if d >= DISTANCE_THRESHOLD]
                    print(f"\nV·ªõi threshold = {DISTANCE_THRESHOLD}:")
                    print(f"  Relevant: {len(relevant_distances)} k·∫øt qu·∫£ ({len(relevant_distances)/len(all_distances)*100:.1f}%)")
                    print(f"  Non-relevant: {len(non_relevant_distances)} k·∫øt qu·∫£ ({len(non_relevant_distances)/len(all_distances)*100:.1f}%)")
                    if relevant_distances:
                        print(f"  Distance trung b√¨nh c·ªßa relevant: {sum(relevant_distances)/len(relevant_distances):.4f}")
                    if non_relevant_distances:
                        print(f"  Distance trung b√¨nh c·ªßa non-relevant: {sum(non_relevant_distances)/len(non_relevant_distances):.4f}")
            
            # Th·ªëng k√™ theo category
            category_stats = {}
            for r in results:
                cat = r["category"]
                if cat not in category_stats:
                    category_stats[cat] = {
                        "count": 0, 
                        "total_precision": 0,
                        "total_ap": 0
                    }
                category_stats[cat]["count"] += 1
                category_stats[cat]["total_precision"] += r.get("precision_at_5", 0.0)
                category_stats[cat]["total_ap"] += r.get("ap_at_5", 0.0)
            
            # Top queries t·ªët nh·∫•t v√† x·∫•u nh·∫•t
            results_with_scores = [(r, r.get("precision_at_5", 0.0), r.get("ap_at_5", 0.0)) for r in results]
            results_with_scores.sort(key=lambda x: (x[1], x[2]), reverse=True)
            
            print(f"\n{'='*80}")
            print("TOP 5 QUERIES T·ªêT NH·∫§T (theo Precision@5)")
            print(f"{'='*80}")
            for i, (r, prec, ap) in enumerate(results_with_scores[:5], 1):
                print(f"{i}. Query ID: {r['query_id']} | Category: {r['category']} | Difficulty: {r['difficulty']}")
                print(f"   Precision@5: {prec:.4f} | AP@5: {ap:.4f} | Relevant: {r.get('num_relevant', 0)}/5")
                print(f"   Query: {r['query_text'][:80]}...")
            
            print(f"\n{'='*80}")
            print("TOP 5 QUERIES X·∫§U NH·∫§T (theo Precision@5)")
            print(f"{'='*80}")
            for i, (r, prec, ap) in enumerate(results_with_scores[-5:], 1):
                print(f"{i}. Query ID: {r['query_id']} | Category: {r['category']} | Difficulty: {r['difficulty']}")
                print(f"   Precision@5: {prec:.4f} | AP@5: {ap:.4f} | Relevant: {r.get('num_relevant', 0)}/5")
                print(f"   Query: {r['query_text'][:80]}...")
            
            print(f"\n{'='*80}")
            print("TH·ªêNG K√ä THEO CATEGORY")
            print(f"{'='*80}")
            for cat, stats in sorted(category_stats.items()):
                avg_prec = stats["total_precision"] / stats["count"]
                avg_ap = stats["total_ap"] / stats["count"]
                # T√≠nh min, max cho category n√†y
                cat_precisions = [r.get("precision_at_5", 0.0) for r in results if r["category"] == cat]
                cat_min = min(cat_precisions) if cat_precisions else 0.0
                cat_max = max(cat_precisions) if cat_precisions else 0.0
                cat_perfect = sum(1 for p in cat_precisions if p == 1.0)
                print(f"  {cat} (n={stats['count']}):")
                print(f"    Precision@5: {avg_prec:.4f} (min: {cat_min:.4f}, max: {cat_max:.4f}, perfect: {cat_perfect})")
                print(f"    AP@5: {avg_ap:.4f}")
            
            # Th·ªëng k√™ theo difficulty
            difficulty_stats = {}
            for r in results:
                diff = r["difficulty"]
                if diff not in difficulty_stats:
                    difficulty_stats[diff] = {
                        "count": 0, 
                        "total_precision": 0,
                        "total_ap": 0
                    }
                difficulty_stats[diff]["count"] += 1
                difficulty_stats[diff]["total_precision"] += r.get("precision_at_5", 0.0)
                difficulty_stats[diff]["total_ap"] += r.get("ap_at_5", 0.0)
            
            print(f"\n{'='*80}")
            print("TH·ªêNG K√ä THEO DIFFICULTY")
            print(f"{'='*80}")
            for diff, stats in sorted(difficulty_stats.items()):
                avg_prec = stats["total_precision"] / stats["count"]
                avg_ap = stats["total_ap"] / stats["count"]
                # T√≠nh min, max cho difficulty n√†y
                diff_precisions = [r.get("precision_at_5", 0.0) for r in results if r["difficulty"] == diff]
                diff_min = min(diff_precisions) if diff_precisions else 0.0
                diff_max = max(diff_precisions) if diff_precisions else 0.0
                diff_perfect = sum(1 for p in diff_precisions if p == 1.0)
                print(f"  {diff} (n={stats['count']}):")
                print(f"    Precision@5: {avg_prec:.4f} (min: {diff_min:.4f}, max: {diff_max:.4f}, perfect: {diff_perfect})")
                print(f"    AP@5: {avg_ap:.4f}")
            
            # Ph√¢n t√≠ch v√† ƒë·ªÅ xu·∫•t threshold
            if EVALUATION_METHOD == "distance" and all_distances:
                print(f"\n{'='*80}")
                print("PH√ÇN T√çCH V√Ä ƒê·ªÄ XU·∫§T THRESHOLD")
                print(f"{'='*80}")
                print(f"Threshold hi·ªán t·∫°i: {DISTANCE_THRESHOLD}")
                print(f"\nPh√¢n t√≠ch v·ªõi c√°c threshold kh√°c nhau:")
                test_thresholds = [0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]
                for thresh in test_thresholds:
                    relevant_count = sum(1 for d in all_distances if d < thresh)
                    relevant_pct = relevant_count / len(all_distances) * 100
                    print(f"  Threshold {thresh:.2f}: {relevant_count}/{len(all_distances)} relevant ({relevant_pct:.1f}%)")
                
                # ƒê·ªÅ xu·∫•t threshold d·ª±a tr√™n ph√¢n v·ªã
                if len(all_distances) >= 10:
                    p25 = distance_sorted[len(distance_sorted) // 4]
                    p50 = median_distance
                    p75 = distance_sorted[len(distance_sorted) * 3 // 4]
                    print(f"\nPh√¢n v·ªã distance:")
                    print(f"  25th percentile (P25): {p25:.4f}")
                    print(f"  50th percentile (Median): {p50:.4f}")
                    print(f"  75th percentile (P75): {p75:.4f}")
                    print(f"\nüí° ƒê·ªÅ xu·∫•t:")
                    print(f"  - Threshold ch·∫∑t ch·∫Ω (P25): {p25:.4f} ‚Üí ~{sum(1 for d in all_distances if d < p25)/len(all_distances)*100:.1f}% relevant")
                    print(f"  - Threshold v·ª´a ph·∫£i (P50): {p50:.4f} ‚Üí ~{sum(1 for d in all_distances if d < p50)/len(all_distances)*100:.1f}% relevant")
                    print(f"  - Threshold l·ªèng (P75): {p75:.4f} ‚Üí ~{sum(1 for d in all_distances if d < p75)/len(all_distances)*100:.1f}% relevant")
            
            # T√≥m t·∫Øt cu·ªëi c√πng
            print(f"\n{'='*80}")
            print("T√ìM T·∫ÆT ƒê√ÅNH GI√Å")
            print(f"{'='*80}")
            print(f"üìä T·ªïng quan:")
            print(f"   - T·ªïng s·ªë queries: {total}")
            print(f"   - Precision@5 trung b√¨nh: {avg_precision_at_5:.4f} ({avg_precision_at_5*100:.2f}%)")
            print(f"   - MAP@5: {map_at_5:.4f} ({map_at_5*100:.2f}%)")
            print(f"   - S·ªë queries ƒë·∫°t perfect (1.0): {perfect_queries}/{total} ({perfect_queries/total*100:.1f}%)")
            print(f"   - S·ªë queries c√≥ Precision@5 >= 0.8: {perfect_queries + high_queries}/{total} ({(perfect_queries + high_queries)/total*100:.1f}%)")
            print(f"\nüìà Ch·∫•t l∆∞·ª£ng:")
            if avg_precision_at_5 >= 0.9:
                print(f"   ‚úì H·ªá th·ªëng ho·∫°t ƒë·ªông R·∫§T T·ªêT (Precision@5 >= 90%)")
            elif avg_precision_at_5 >= 0.8:
                print(f"   ‚úì H·ªá th·ªëng ho·∫°t ƒë·ªông T·ªêT (Precision@5 >= 80%)")
            elif avg_precision_at_5 >= 0.7:
                print(f"   ‚ö† H·ªá th·ªëng ho·∫°t ƒë·ªông KH√Å (Precision@5 >= 70%)")
            else:
                print(f"   ‚ö† H·ªá th·ªëng c·∫ßn C·∫¢I THI·ªÜN (Precision@5 < 70%)")
            
            if EVALUATION_METHOD == "distance":
                print(f"\n‚öôÔ∏è  C·∫•u h√¨nh ƒë√°nh gi√°:")
                print(f"   - Ph∆∞∆°ng ph√°p: Distance-based")
                print(f"   - Threshold: {DISTANCE_THRESHOLD}")
                print(f"   - Ti√™u ch√≠: distance < {DISTANCE_THRESHOLD} ‚Üí relevant")
            else:
                print(f"\n‚öôÔ∏è  C·∫•u h√¨nh ƒë√°nh gi√°:")
                print(f"   - Ph∆∞∆°ng ph√°p: Relevance score-based")
                print(f"   - Threshold: {RELEVANCE_THRESHOLD}")
                print(f"   - Ti√™u ch√≠: relevance score >= {RELEVANCE_THRESHOLD} ‚Üí relevant")
        
        # L∆∞u k·∫øt qu·∫£ cu·ªëi c√πng
        save_results(results)
        print(f"\nƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {RESULTS_FILE}")
        print(f"ƒê√£ l∆∞u k·∫øt qu·∫£ t√¨m ki·∫øm ƒë·ªÉ ƒë√°nh gi√° v√†o: {SEARCH_RESULTS_FILE}")
        
        # X√≥a file progress v√¨ ƒë√£ xong
        if PROGRESS_FILE.exists():
            PROGRESS_FILE.unlink()
            print("ƒê√£ x√≥a file progress.")
    else:
        print(f"\nƒê√£ x·ª≠ l√Ω {len(queries_to_process)} queries trong batch n√†y.")
        print(f"C√≤n l·∫°i {len(all_queries) - end_index} queries.")
        print(f"Ch·∫°y l·∫°i script ƒë·ªÉ ti·∫øp t·ª•c t·ª´ query {end_index + 1}")


# ============================================================================
# CH·∫†Y CH∆Ø∆†NG TR√åNH
# ============================================================================

if __name__ == "__main__":
    try:
        process_queries()
    except KeyboardInterrupt:
        print("\n\nƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng (Ctrl+C). Progress ƒë√£ ƒë∆∞·ª£c l∆∞u.")
    except Exception as e:
        print(f"\nL·ªói: {e}")
        import traceback
        traceback.print_exc()

